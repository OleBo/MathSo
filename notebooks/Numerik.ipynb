{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bffe48d8",
   "metadata": {},
   "source": [
    "# Numerik\n",
    "\n",
    "## Einleitung\n",
    "\n",
    "### Was ist Numerik?\n",
    "\n",
    "-   Numerische Mathematik befasst sich damit, für mathematisch\n",
    "    formulierte Probleme einen rechnerischen Lösungsweg zu finden.\n",
    "\n",
    "-   Solch ein rechnerischer Lösungsweg heißt **Algorithmus**:\n",
    "    eine für alle möglichen Eingabedaten eindeutig festgelegte Abfolge\n",
    "    elementarer Rechenoperationen (inkl. Auswertung logischer\n",
    "    Bedingungen und mathematischer Funktionen).\n",
    "\n",
    "-   Numerik kommt zum Einsatz, wenn eine analytische Lösung nicht\n",
    "    möglich ist oder diese in einer für die Berechnung unbrauchbaren\n",
    "    Form vorliegt.\n",
    "\n",
    "-   Interdisziplinär: Mathematik (Analysis, Lineare Algebra),\n",
    "    Informatik, Anwendungen z.B. in den Wirtschafts- oder\n",
    "    Naturwissenschaften\n",
    "\n",
    "### Vom Problem zur Lösung\n",
    "\n",
    "-   **Modellierung:** Formulierung des Anwendungsproblems als\n",
    "    mathematisches Modell, idealisierte Annahmen\n",
    "\n",
    "-   **Realisierung:** Wahl der Lösungsmethode/des Algorithmus,\n",
    "    Implementierung, Suche/Entwicklung geeigneter Software,\n",
    "    Datenorganisation, Visualisierung\n",
    "\n",
    "-   **Validierung:** Überprüfen des Modells auf seine Gültigkeit, des\n",
    "    Programms auf seine Zuverlässigkeit, des numerischen Verfahrens auf\n",
    "    seine Stabilität; falls möglich, Fehlerabschätzung für konkrete\n",
    "    Rechnungen\n",
    "\n",
    "### Vom Problem zur Lösung: Beispiel\n",
    "\n",
    "1. **Anwendungsproblem**: Bewertung von Finanzoptionen\n",
    "2. **Finanzmath. Modell**: Black-Scholes-Modell\n",
    "3. **Mathematisches Modell**: Partielle Differentialgleichung\n",
    "4. **Numerisches Verfahren**: Diskretisierung: z.B. finite Differenzen,numerische Methoden für Systemegewöhnlicher Differentialgleichungen\n",
    "5. **Algorithmus**: Ablauf der einzelnen Rechenschritte\n",
    "6. **Programm**: Programmiersprache, Eigene oder Fremdsoftware, Ein- und Ausgabe, Datenorganisation, Visualisierung\n",
    "7. **Rechnung**: Simulation mit konkreten Eingabedaten, Visualisierung\n",
    "8. **Fehleranalyse**: Abschätzung für die konkreten Daten, Konvergenztests\n",
    "\n",
    "### Fehlerarten\n",
    "\n",
    "-   Bei der Implementierung auf einem Computer ist zu bedenken:\n",
    "\n",
    "    -   Die zur Verfügung stehende *Zahlenmenge* ist endlich, die\n",
    "        Rechengenauigkeit daher begrenzt.\n",
    "\n",
    "    -   Der *Speicher* ist endlich, reelle Funktionen können z.B. nur\n",
    "        approximativ dargestellt werden.\n",
    "\n",
    "    -   Die *Rechenzeit* ist beschränkt, das Problem kann daher oft nur\n",
    "        näherungsweise (approximativ) gelöst werden.\n",
    "\n",
    "-   Dies führt zu verschiedenen Arten von Fehlern:\n",
    "\n",
    "    -   **Rundungsfehler** durch endliche Maschinengenauigkeit\n",
    "\n",
    "    -   **Diskretisierungsfehler** durch endliche Approximation\n",
    "\n",
    "    -   **Verfahrensfehler** durch bei der Konstruktion des\n",
    "        Algorithmus angenommene Vereinfachungen\n",
    "\n",
    "-   Daneben können auch die **Eingabedaten** mit Fehlern behaftet\n",
    "    sein, z.B. Messfehler oder Fehler statistischer Natur.\n",
    "\n",
    "-   Die Abschätzung des Einflusses dieser Fehler auf das Ergebnis ist\n",
    "    eine wichtige Aufgabe der Numerik.\n",
    "    \n",
    "<img src=\"figs/notebook.png\" alt=\"notebook\"\n",
    "\ttitle=\"Beispiel für Rundungsfehler\" width=\"50\" height=\"50\" />\n",
    "\n",
    "#### Beispiel zu Rundungsfehlern\n",
    "\n",
    "Approximiere $\\lim_{x\\to 0} f(x)$ mit\n",
    "$$f(x) := \\frac{1-\\cos x}{x^2}$$\n",
    "durch Auswertung für $x=10^{-n}$, $n=1,2,\\ldots$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82ed6839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x      f(x)           \n",
      "1e-01  0.49958347219742893\n",
      "1e-02  0.4999958333473664\n",
      "1e-03  0.49999995832550326\n",
      "1e-04  0.4999999969612645\n",
      "1e-05  0.5000000413701854\n",
      "1e-06  0.5000444502911705\n",
      "1e-07  0.4996003610813205\n",
      "1e-08  0.0            \n",
      "1e-09  0.0            \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def f(x):\n",
    "    return (1. - np.cos(x))/x**2\n",
    "\n",
    "x = np.array([10**(-n) for n in range(1,10)])\n",
    "y = f(x)\n",
    "print(\"{:<6} {:<15}\".format(\"x\", \"f(x)\"))\n",
    "for xk, yk in zip(x, y):\n",
    "    print(\"{:<6.0e} {:<15}\".format(xk, yk))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c3922d",
   "metadata": {},
   "source": [
    "### Absoluter und relativer Fehler\n",
    "\n",
    "Sei $x\\in\\mathbb{R}$ und $\\tilde x$ ein Näherungswert für $x$. Dann\n",
    "heißen \n",
    "- $\\delta_x := \\tilde x - x$ **absoluter Fehler** von $x$\n",
    "und, \n",
    "- falls $x\\neq 0$, $$\\varepsilon_x := \\frac{\\tilde x - x}{x}$$ **relativer Fehler** von $x$.\n",
    "\n",
    "**Beispiel** (Analysis 2):\n",
    "\n",
    "$x:=40! = 8.15915\\cdot 10^{47}$, und die Stirling-Formel liefert den\n",
    "Näherungswert $\\tilde x = 8.14217\\cdot 10^{47}$.\\\n",
    "Der relative Fehler ist $\\varepsilon_x = 2.081\\cdot 10^{-3}$, der\n",
    "absolute Fehler $\\delta_x = 1.698\\cdot 10^{45}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f056781c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "absolute error: 1.6980000000000836e+45\n",
      "relative error: 0.0020810991341010813\n"
     ]
    }
   ],
   "source": [
    "from math_so.utils import absolute_error, relative_error\n",
    "value =8.15915e47\n",
    "approx=8.14217e47\n",
    "print('absolute error: {}'.format(absolute_error(value, approx)))\n",
    "print('relative error: {}'.format(relative_error(value, approx)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44fa4c0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This function will calculate the absolute error:\n",
      "\n",
      "    .. math:: \\epsilon = \\left|v - v_{approx}\\right|\n",
      "        :label: absolute_error\n",
      "\n",
      "    :value: some value :math:`v`\n",
      "    :approx: :math:`v_{approx}` approximation of :math:`v`\n",
      "    :returns: absolute error :math:`\\epsilon` according equation :eq:\n",
      "    `absolute_error`\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(absolute_error.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aebc1d45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This function will calculate the relative error:\n",
      "\n",
      "    .. math:: \\eta = \\left|\\frac{v - v_{approx}}{v}\\right|\n",
      "        :label: relative_error\n",
      "\n",
      "    This is also the normalized absolute error (see equation :eq:\n",
      "    `absolute_error`). There are two features that should be kept in mind:\n",
      "\n",
      "    - Relative error is undefined when the true value is zero as it appears in\n",
      "      the denominator.\n",
      "    - Relative error only makes sense when measured on a ratio scale, (i.e. a\n",
      "      scale which has a true meaningful zero), otherwise it would be sensitive\n",
      "      to the measurement units.\n",
      "\n",
      "    :value: some value :math:`v`\n",
      "    :approx: :math:`v_{approx}` approximation of :math:`v`\n",
      "    :returns: relative error :math:`\\eta` according equation :eq:\n",
      "    `relative_error`\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(relative_error.__doc__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d58f4d8",
   "metadata": {},
   "source": [
    "## Computerarithmetik und Fehlerrechnung\n",
    "\n",
    "### Zahldarstellung\n",
    "\n",
    "Sei $b\\in\\mathbb{N}$, $b>1$ eine vorgegebene **Basis**. Dann lässt\n",
    "sich jede reelle Zahl $x$ im **Stellenwertsystem** zur Basis $b$\n",
    "(oder auch: **$b$-adischen Zahlensystem**) eindeutig schreiben\n",
    "als\n",
    "\n",
    "$$x = \\sum_{k=-\\infty}^n a_k b^k =: (a_n a_{n-1} \\ldots a_1 a_0 \\, . \\, a_{-1} a_{-2} \\ldots)_b$$\n",
    "\n",
    "für ein $n\\in\\mathbb{Z}$. Hierbei heißen $0 \\leqslant a_k < b$ die\n",
    "**Ziffern**, $a_n a_{n-1} \\ldots a_1 a_0$ die\n",
    "**Vorkommastellen** und $a_{-1} a_{-2} \\ldots$ die\n",
    "**Nachkommastellen**.\n",
    "\n",
    "Für $p=10$ erhält man das **Dezimalsystem**, für $p=2$ das\n",
    "**Dualsystem**.\n",
    "\n",
    "**Beispiel**: $$20.21 = (20.21)_{10} = (10100.001101 \\ldots)_2$$\n",
    "\n",
    "<img src=\"figs/tafel.png\" alt=\"Tafel\"\n",
    "\ttitle=\"Umrechnung zwischen verschiedenen Basen\" width=\"50\" height=\"50\" />\n",
    "\n",
    "Zur Basis $b$ läßt sich jede reelle Zahl $x$ schreiben als\n",
    "$$x = s \\cdot m \\cdot b^e$$ mit dem **Vorzeichen** $s=\\pm 1$, der\n",
    "**Mantisse** $m\\in\\mathbb{R}$, $1\\leqslant m < b$ und dem\n",
    "**Exponenten** $e\\in\\mathbb{Z}$.\n",
    "\n",
    "**Beispiel:** $$\\begin{aligned}\n",
    "     &&20.21 = + 2.021 \\cdot 10^1 \\\\\n",
    "     &&= (10100.001101 \\ldots)_2 = (+ 1.0100001101\\ldots \\cdot 2^{100})_2,      \n",
    "  \\end{aligned}$$ wobei wir auch den Exponenten im Dualsystem\n",
    "geschrieben haben: $e = (100)_2 = (4)_{10}$.\n",
    "\n",
    "Computer basieren auf dem Dualsystem ($b=2$) und reservieren für jede\n",
    "Zahl eine feste Speichergröße:\\\n",
    "\n",
    "  ------------ ------------------ ------------------------------ ------------------\n",
    "  Vorzeichen   $s = (-1)^S$,      $S\\in\\{0,1\\}$,                 1 Bit für $S$\n",
    "  Mantisse     $m = 1 + M/2^p$,   $M\\in\\{0,1,\\ldots2^p-1\\}$,     $p$ Bits für $M$\n",
    "  Exponent     $e = E - B$,       $E\\in\\{0,1,\\ldots,2^r-1\\}$ ,   $r$ Bits für $E$\n",
    "  ------------ ------------------ ------------------------------ ------------------\n",
    "\n",
    "\\\n",
    "wobei der **Bias** $B=2^{r-1}-1$ gewählt wird, so dass gleich\n",
    "viele positive wie negative Exponenten gespeichert werden können.\\\n",
    "So erhält man den **Raum der Maschinenzahlen** $M(2,p,r)$.\\\n",
    "Analog für andere Basen $b$.\n",
    "\n",
    "**Beispiel:** In $M(2,8,4)$ gilt für\n",
    "$(20.21)_{10} = (1.0100001101\\ldots \\cdot 2^{100})_2$: $$\\begin{aligned}\n",
    "    s = +1 \\; &\\Rightarrow& \\; S = (0)_2 \\\\\n",
    "    m = (1.01000011\\ldots)_2 \\; &\\Rightarrow& M = (01000011)_2 \\\\\n",
    "    e = (100)_2 = (4)_{10}, \\; B = (7)_{10} \\; &\\Rightarrow& \\; E = e + B = (11)_{10} = (1011)_2\n",
    "  \\end{aligned}$$\n",
    "\n",
    "a)  Die kleinste Maschinenzahl im $M(2,p,r)$, die größer als $1$ ist,\n",
    "    erhält man für\n",
    "    $$E = B, \\, M = 1 \\; \\Rightarrow \\; x = 1 + 2^{-p} =: 1 + 2\\mathsf{eps},$$\n",
    "    wobei $\\mathsf{eps}:= 2^{-p-1}$ **Maschinengenauigkeit**\n",
    "    heißt.\n",
    "\n",
    "b)  Die größte Zahl in $M(2,p,r)$ erhält man für\n",
    "    $$E = 2^r - 1, \\, M = 2^p - 1 \\; \\Rightarrow \\; x = (2 - 2^{-p}) \\, 2^{2^{r-1}} =: \\mathsf{realmax}.$$\n",
    "\n",
    "c)  Die betragsmäßig kleinste Zahl in $M(2,p,r)$ erhält man für[^4]\n",
    "    $$E = 0, M = 0 \\; \\Rightarrow \\; x = 2^{-2^{r-1} + 1} =: \\mathsf{realmin}.$$\n",
    "\n",
    "<img src=\"figs/tafel.png\" alt=\"Tafel\"\n",
    "\ttitle=\"Erläuterungen\" width=\"50\" height=\"50\" />\n",
    "\n",
    "#### Definition 2.5 (IEEE 754-Norm)\n",
    "\n",
    "In der Norm IEEE 754 (Institute of Electrical and Electronic Engineers,\n",
    "1985/1989) werden u.a. folgende Datentypen festgelegt:\\\n",
    "\n",
    "| Type   | Größe $1+r+p$   | $r$ | $p$ | $\\mathsf{eps}$ | $\\mathsf{realmax}$ | $\\mathsf{realmin}$ |\n",
    "|--------|-----------------|-----|-----|----------------|--------------------|--------------------|\n",
    "| single | 32 bit = 4 byte | 8   | 23  | 6              | 3                  | 1                  |\n",
    "| double | 64 bit = 8 byte | 11  | 52  | 1              | 1                  | 2                  |\n",
    "\n",
    "\n",
    "| Type   | Größe~$1+r+p$      | $r$  | $p$  | $\\mathsf{eps}$       |\n",
    "|:-------|:-------------------|:-----|:-----|:---------------------|\n",
    "| single | $32$ bit $=4$ byte | $8$  | $23$ | $6.0\\cdot 10^{-8}$   |\n",
    "| double | $64$ bit $=8$ byte | $11$ | $52$ | $1.1\\cdot 10^{-16}$  |\n",
    "\n",
    "<img src=\"figs/notebook.png\" alt=\"notebook\"\n",
    "\ttitle=\"Gleitkommazahlen in Python\" width=\"50\" height=\"50\" />\n",
    "\n",
    "#### Gleitkommazahlen in Python\n",
    "\n",
    "Beispiele: $x = 3.45\\cdot 10^{67}$, $y = 1.23\\cdot 10^{-4}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12c3e2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.float_info.epsilon?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c5df9aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.45e+67 0.000123\n"
     ]
    }
   ],
   "source": [
    "x = 3.45e67  \n",
    "y = 1.23e-4\n",
    "print(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b563b74",
   "metadata": {},
   "source": [
    "Der von Python standardmäßig verwendete Datentyp ``float`` entspricht dem IEEE-754-Standard ``double``.\n",
    "\n",
    "Beispiel: Maschinengenauigkeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5aa0c14d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0000000000000002"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = 2e-16\n",
    "1+x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "068535eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 + .5*x #nicht mehr von 1 unterscheidbar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c74b2d",
   "metadata": {},
   "source": [
    "Beispiel: größte darstellbare Zahl "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8dcef5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1e+308"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1e308"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35768322",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "inf"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2e308"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e63372",
   "metadata": {},
   "source": [
    "#### Definition 2.6 (Runden)\n",
    "\n",
    "Bei arithmetischen Rechenoperationen in $M(b,p,r)$ wird das Ergebnis $x$\n",
    "auf einen eindeutig definierten Wert $\\mathsf{rd}(x)\\in M(b,p,r)$\n",
    "gerundet.\\\n",
    "I.A. ist dies die Zahl in $M(b,p,r)$ mit dem kleinsten Abstand zu $x$\n",
    "*(round to nearest)*.\\\n",
    "Falls diese Vorschrift nicht eindeutig ist, gibt es verschiedene\n",
    "Möglichkeiten (Auf-/Abrunden). Gemäß IEEE 754 (mit $b=2$) wird dann die\n",
    "Zahl gewählt, deren letzte Mantissenstelle $0$ ist *(ties to even)*.\n",
    "\n",
    "<img src=\"figs/tafel.png\" alt=\"Tafel\"\n",
    "\ttitle=\"Beispiel\" width=\"50\" height=\"50\" />\n",
    "    \n",
    "#### Satz 2.7 (Rundungsfehler)\n",
    "\n",
    "Es gilt\n",
    "$\\mathsf{rd}(x) = x(1 + \\varepsilon)$ mit\n",
    "$|\\varepsilon| \\leqslant \\mathsf{eps}$,\\\n",
    "d.h. für den *relativen* Rundungsfehler gilt\n",
    "$|\\varepsilon_x| \\leqslant \\mathsf{eps}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db545bb1",
   "metadata": {},
   "source": [
    "Um Rundungsfehler deutlicher zu sehen, importieren wir eine Hilfsfunktion, die auf $p$ signifikante Dezimalstellen rundet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c9f17d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rounding a number to n significant digits.\n",
      "\n",
      "    Rounds a number and includes only the desired number of significant digits.\n",
      "\n",
      "    Use `round(number, ndigits)` with `number` as the number being rounded\n",
      "    and `ndigits` as the number of significant digits minus\n",
      "    `(int(math.floor(math.log10(abs(number)))) - 1)`.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "from math_so.utils import signif\n",
    "print(signif.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ee69bf4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00123\n",
      "-1230.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "#Beispiel\n",
    "print(signif(0.0012345, 3))\n",
    "print(signif(-1234.5, 3))\n",
    "print(signif(0, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66027530",
   "metadata": {},
   "source": [
    "## Fehlerfortpflanzung\n",
    "\n",
    "<img src=\"figs/tafel.png\" alt=\"Tafel\"\n",
    "\ttitle=\"Beispiel zum Einfluss algebraischer Umformungen auf Rundungsfehler\" width=\"50\" height=\"50\" />\n",
    "\n",
    "Das Folgende gilt allgemein für alle Arten von Fehlern.\\\n",
    "\n",
    "Es seien $x_1$ und $x_2$ fehlerbehaftete Größen. Dann gilt\n",
    "$$\\begin{array}{llll}\n",
    "      y = x_1 \\pm x_2 &\\Rightarrow & {\\delta_y = \\delta_{x_1} \\pm \\delta_{x_2}}, &\n",
    "      \\varepsilon_y = \\dfrac{x_1 \\varepsilon_{x_1} \\pm x_2 \\varepsilon_{x_2}}{x_1\\pm x_2} ,\\medskip\\\\\n",
    "      y = x_1 \\cdot x_2 &\\Rightarrow & \\delta_y \\doteq x_2 \\delta_{x_1} + x_1 \\delta_{x_2}, &{\\varepsilon_y \\doteq \\varepsilon_{x_1} + \\varepsilon_{x_2}}, \\medskip\\\\\n",
    "      y = \\dfrac{x_1}{x_2} &\\Rightarrow & \\delta_y \\doteq \\dfrac{x_2 \\delta_{x_1} - x_1 \\delta_{x_2}}{x_2^2}, & {\\varepsilon_y \\doteq \\varepsilon_{x_1} - \\varepsilon_{x_2}},\n",
    "    \\end{array}$$ wobei $\\doteq$ die Vernachlässigung quadratischer\n",
    "Fehlerterme andeutet.\n",
    "\n",
    "Bei Addition (Subtr.) werden also die *absoluten* Fehler addiert\n",
    "(subtr.),\\\n",
    "bei Multiplikation (Division) die *relativen* Fehler addiert\n",
    "(subtrahiert).\\\n",
    "\n",
    "<img src=\"figs/tafel.png\" alt=\"Tafel\"\n",
    "\ttitle=\"Beweis\" width=\"50\" height=\"50\" />\n",
    "\n",
    "[\\[s:fehlerfkt1d\\]]{#s:fehlerfkt1d label=\"s:fehlerfkt1d\"} Es sei\n",
    "$I\\subset \\mathbb{R}$ ein offenes Intervall, $f:I\\to\\mathbb{R}$ eine\n",
    "differenzierbare Funktion, $x\\in I$ und $y = f(x)$. Dann gilt\n",
    "\n",
    "a)  $\\delta_y = f'(x) \\delta_x$\n",
    "\n",
    "b)  $\\varepsilon_y = K_x \\varepsilon_x$, wobei\n",
    "    $K_x := \\dfrac{x f'(x)}{f(x)}$ **(relative) Konditionszahl**\n",
    "    heißt.\n",
    "\n",
    "<img src=\"figs/tafel.png\" alt=\"Tafel\"\n",
    "\ttitle=\"Beweis, Beispiel\" width=\"50\" height=\"50\" />\n",
    "\n",
    "Für $|K_x| > 1$ verstärkt sich der relative Fehler bei Anwendung der\n",
    "Funktion $f$ also, das Problem heißt dann **schlecht konditioniert**.\n",
    "\n",
    "## Lineare Gleichungssysteme: Direkte Methoden\n",
    "\n",
    "### Der Gauß-Algorithmus\n",
    "\n",
    "-   Zu lösen ist ein lineares Gleichungssystem (LGS)\n",
    "    $$\\sum_{k=1}^n a_{ik} x_k = b_i, \\quad i=1,2,\\ldots,n$$ mit $n$\n",
    "    Gleichungen in $n$ Unbekannten $x_k$, mit\n",
    "    $a_{ik}, b_i \\in\\mathbb{R}$\n",
    "\n",
    "-   In Matrixform:\n",
    "    $$Ax = b, \\quad A=(a_{ik}) \\in\\mathbb{R}^{n\\times n}, \\quad b = (b_i) \\in \\mathbb{R}^n$$\n",
    "\n",
    "-   Wir setzen voraus, dass $A$ regulär (invertierbar) ist, so dass eine\n",
    "    eindeutige Lösung $x\\in\\mathbb{R}^n$ existiert.\n",
    "\n",
    "-   Ziel des **Gauß'schen Eliminationsverfahrens** ist, die\n",
    "    erweiterte Koeffizientenmatrix $(A|b)$ durch elementare\n",
    "    Zeilenumformungen auf eine obere Dreiecksmatrix zu transformieren:\n",
    "\n",
    "    -   Multiplikation einer Zeile mit einer Zahl $\\neq 0$\n",
    "\n",
    "    -   Addition eines Vielfachen einer Zeile zu einer anderen\n",
    "\n",
    "    -   Vertauschung von Zeilen \\[verwenden wir zunächst noch nicht!\\]\n",
    "\n",
    "-   Dabei bleibt der Lösungsraum invariant.\n",
    "\n",
    "<img src=\"figs/tafel.png\" alt=\"Tafel\"\n",
    "\ttitle=\"Beispiel\" width=\"50\" height=\"50\" />\n",
    "\n",
    "[\\[algo:gaussnaiv\\]]{#algo:gaussnaiv label=\"algo:gaussnaiv\"}\n",
    "$$\\begin{aligned}\n",
    "        &a_{ij}^{(0)} = a_{ij}, \\quad b_i^{(0)} = b_i\\\\\n",
    "        &\\text{Für } k=1,\\ldots, n-1:\\\\\n",
    "        &\\qquad \\text{Für } i=k+1,\\ldots, n:\\\\\n",
    "        &\\qquad\\qquad \\ell_{ik} = \\frac{a_{ik}^{(k-1)}}{a_{kk}^{(k-1)}}\\\\\n",
    "        &\\qquad\\qquad b_i^{(k)} = b_i^{(k-1)} - \\ell_{ik} b_k^{(k-1)}\\\\\n",
    "        &\\qquad\\qquad a_{ik}^{(k)} = 0\\\\\n",
    "        &\\qquad\\qquad \\text{Für } j = k+1,\\ldots, n:\\\\\n",
    "        &\\qquad\\qquad\\qquad a_{ij}^{(k)} = a_{ij}^{(k-1)} - \\ell_{ik} a_{kj}^{(k-1)} \n",
    "      \\end{aligned}$$\n",
    "\n",
    "<img src=\"figs/tafel.png\" alt=\"Tafel\"\n",
    "\ttitle=\"Herleitung\" width=\"50\" height=\"50\" />\n",
    "\n",
    "Algorithmus [\\[algo:gaussnaiv\\]](#algo:gaussnaiv){reference-type=\"ref\"\n",
    "reference=\"algo:gaussnaiv\"} ist durchführbar, wenn\n",
    "$a_{kk}^{(k-1)} \\neq 0$ für $k=1, \\ldots, n-1$. Dann erhält man im\n",
    "letzten Schritt $$A^{(n-1)} x = b^{(n-1)} =: y$$ mit einer oberen\n",
    "Dreiecksmatrix $$A^{(n-1)} =: U =  \\left( \\begin{array}{cccc} \n",
    "    u_{11} & u_{12} & \\cdots & u_{1n}\\smallskip\\\\\n",
    "    0 & u_{22} & \\cdots & u_{2n}\\smallskip\\\\\n",
    "    \\vdots & \\ddots & \\ddots & \\vdots\\smallskip\\\\\n",
    "    0 & \\cdots & 0 & u_{nn}             \n",
    "  \\end{array} \\right).$$ Das System $Ux = y$ lässt sich nun leicht\n",
    "lösen:\n",
    "\n",
    "$$\\begin{aligned}\n",
    "      &\\text{Für } i = n, n-1, \\ldots, 1:\\\\\n",
    "      &\\qquad x_i = \\frac{1}{u_{ii}} \\left(y_i\n",
    "        - \\sum_{j=i+1}^n u_{ij} x_j \\right)\n",
    "    \\end{aligned}$$\n",
    "\n",
    "In der Herleitung von Algorithmus\n",
    "[\\[algo:gaussnaiv\\]](#algo:gaussnaiv){reference-type=\"ref\"\n",
    "reference=\"algo:gaussnaiv\"} haben wir auch bereits gezeigt:\n",
    "\n",
    "[\\[satz:LUnaiv\\]]{#satz:LUnaiv label=\"satz:LUnaiv\"} Ist Algorithmus\n",
    "[\\[algo:gaussnaiv\\]](#algo:gaussnaiv){reference-type=\"ref\"\n",
    "reference=\"algo:gaussnaiv\"} durchführbar, so erhält man die Zerlegung\n",
    "$A=LU$ mit $$L = \\left( \\begin{array}{ccccc}\n",
    "        1 & 0 & 0 & \\cdots & 0\\\\\n",
    "        \\ell_{21} & 1 & 0 & \\ddots & 0 \\\\\n",
    "        \\ell_{31} & \\ell_{32} & 1 & \\cdots & 0 \\\\\n",
    "        \\vdots & \\vdots & \\vdots & \\ddots & \\vdots\\\\\n",
    "        \\ell_{n-1} & \\ell_{n2} & \\ell_{n3} & \\cdots & 1             \n",
    "        \\end{array} \\right), \\quad\n",
    "      U =  \\left( \\begin{array}{cccc} \n",
    "        u_{11} & u_{12} & \\cdots & u_{1n}\\smallskip\\\\\n",
    "        0 & u_{22} & \\cdots & u_{2n}\\smallskip\\\\\n",
    "        \\vdots & \\ddots & \\ddots & \\vdots\\smallskip\\\\\n",
    "        0 & \\cdots & 0 & u_{nn}             \n",
    "      \\end{array} \\right),$$ wobei $u_{ij} = a_{ij}^{(n-1)}$ und\n",
    "$\\ell_{ik}$ wie in Algorithmus\n",
    "[\\[algo:gaussnaiv\\]](#algo:gaussnaiv){reference-type=\"ref\"\n",
    "reference=\"algo:gaussnaiv\"} definiert.\n",
    "\n",
    "Hat man mit der Gauß-Elimination eine Zerlegung $A=LU$ gefunden, so\n",
    "lässt sich das LGS $Ax=b$ in zwei Schritten lösen:\n",
    "\n",
    "1.  Vorwärtssubstitution: Löse $Ly = b$ nach $y$\n",
    "\n",
    "2.  Rückwärtssubstitution: Löse $Ux = y$ nach $x$\n",
    "\n",
    "Die Vorwärtssubstitution lautet ausgeschrieben:\n",
    "\n",
    "$$\\begin{aligned}\n",
    "      &\\text{Für } i = 1,2, \\ldots, n:\\\\\n",
    "      &\\qquad y_i = \\frac{1}{\\ell_{ii}} \\left( b_i - \\sum_{j=1}^{i-1} \\ell_{ij} y_j \\right)\n",
    "    \\end{aligned}$$\n",
    "\n",
    "(Hier haben wir beliebige Diagonalelelemente $\\ell_{ii}\\neq 0$\n",
    "zugelassen.)\n",
    "\n",
    "Algorithmus [\\[algo:gaussnaiv\\]](#algo:gaussnaiv){reference-type=\"ref\"\n",
    "reference=\"algo:gaussnaiv\"} versagt, wenn $a_{kk}^{(k-1)} = 0$ für ein\n",
    "$k\\in\\{1, \\ldots, n-1\\}$. Aber wir haben Zeilenvertauschungen noch nicht\n",
    "ins Spiel gebracht:\n",
    "\n",
    "Für eine reguläre Matrix $A$ existiert vor dem $k$-ten\n",
    "Eliminationsschritt von Algorithmus\n",
    "[\\[algo:gaussnaiv\\]](#algo:gaussnaiv){reference-type=\"ref\"\n",
    "reference=\"algo:gaussnaiv\"} stets eine Zeilenvertauschung derart, dass\n",
    "danach das $k$-te Diagonalelement $a_{kk}^{(k-1)}$ nicht Null ist.\\\n",
    "Dieses bezeichnet man auch als **Pivotelement**.\n",
    "\n",
    "<img src=\"figs/tafel.png\" alt=\"Tafel\"\n",
    "\ttitle=\"Beispiel, Beweis\" width=\"50\" height=\"50\" />\n",
    "\n",
    "[\\[algo:gaussperm\\]]{#algo:gaussperm label=\"algo:gaussperm\"}\n",
    "$$\\begin{aligned}\n",
    "      &a_{ij}^{(0)} = a_{ij}, \\quad b_i^{(0)} = b_i\\\\\n",
    "      &\\text{Für } k=1,\\ldots, n-1:\\\\\n",
    "      &\\qquad \\text{Wähle Pivot } p_k \\in\\{k,\\ldots, n\\} \\text{ derart, dass } a_{p_k k}^{(k-1)} \\neq 0 \\\\\n",
    "      &\\qquad \\text{Falls } p_k \\neq k, \\text{ vertausche } a_{kj}^{(k-1)}\\leftrightarrow a_{p_k j}^{(k-1)} \\text{ für } j=k,\\ldots, n,\\\\\n",
    "      &\\hspace{3.1cm} b_k^{(k-1)} \\leftrightarrow b_{p_k}^{(k-1)} \\text{ und } \\ell_{kj}\\leftrightarrow\\ell_{p_k j}\\text{ für } j=1,\\ldots,k-1 \\\\ \n",
    "      &\\qquad \\text{Für } i=k+1,\\ldots, n:\\\\\n",
    "      &\\qquad\\qquad \\ell_{ik} = \\frac{a_{ik}^{(k-1)}}{a_{kk}^{(k-1)}}\\\\\n",
    "      &\\qquad\\qquad b_i^{(k)} = b_i^{(k-1)} - \\ell_{ik} b_k^{(k-1)}\\\\\n",
    "      &\\qquad\\qquad a_{ik}^{(k)} = 0\\\\\n",
    "      &\\qquad\\qquad \\text{Für } j = k+1,\\ldots, n:\\\\\n",
    "      &\\qquad\\qquad\\qquad a_{ij}^{(k)} = a_{ij}^{(k-1)} - \\ell_{ik} a_{kj}^{(k-1)} \n",
    "    \\end{aligned}$$\n",
    "\n",
    "Satz [\\[satz:LUnaiv\\]](#satz:LUnaiv){reference-type=\"ref\"\n",
    "reference=\"satz:LUnaiv\"} muss entsprechend angepasst werden:\n",
    "\n",
    "Zu jeder regulären Matrix $A$ existieren eine Permutationsmatrix $P$,\n",
    "eine linke untere Dreiecksmatrix $L$ mit Diagonale $1$ und eine rechte\n",
    "obere Dreiecksmatrix $U$, so dass $$PA = LU.$$\n",
    "\n",
    "Mit Algorithmus\n",
    "[\\[algo:gaussperm\\]](#algo:gaussperm){reference-type=\"ref\"\n",
    "reference=\"algo:gaussperm\"} erhält man diese als $U = A^{(n-1)}$, und\n",
    "$L$ ist die Dreiecksmatrix aus den $\\ell_{ik}$. Die Permutationsmatrix\n",
    "$P$ erhält man, indem man die Zeilenvertauschungen in der gleichen\n",
    "Reihenfolge auf die Einheitsmatrix anwendet.\n",
    "\n",
    "Hat man eine Zerlegung $PA=LU$ gefunden, lässt sich das LGS $Ax=b$ in\n",
    "drei Schritten lösen:\n",
    "\n",
    "1.  Zeilenvertauschungen der rechten Seite: Setze $b \\leftarrow P b$\n",
    "\n",
    "2.  Vorwärtssubstitution: Löse $Ly = b$ nach $y$\n",
    "\n",
    "3.  Rückwärtssubstitution: Löse $Ux = y$ nach $x$\n",
    "\n",
    "In der Praxis kann man anstelle von $P$ auch einfach die Pivotindizes\n",
    "$p_k$ aus Algorithmus\n",
    "[\\[algo:gaussperm\\]](#algo:gaussperm){reference-type=\"ref\"\n",
    "reference=\"algo:gaussperm\"} speichern, dann lautet Schritt 1\n",
    "ausgeschrieben:\n",
    "\n",
    "$$\\begin{aligned}\n",
    "      &\\text{Für } k = 1,2, \\ldots, n-1:\\\\\n",
    "      &\\qquad \\text{Falls } p_k\\neq k: \\text{ Vertausche } b_k \\leftrightarrow b_{p_k}\n",
    "    \\end{aligned}$$\n",
    "\n",
    "#### Pivotstrategien\n",
    "\n",
    "Wie wählt man im $k$-ten Schritt die Pivotzeile $p_k$? Nicht alle sind\n",
    "numerisch gleich gut geeignet!\\\n",
    "\n",
    "<img src=\"figs/tafel.png\" alt=\"Tafel\"\n",
    "\ttitle=\"Beispiel\" width=\"50\" height=\"50\" />\n",
    "\n",
    "Die **Diagonalstrategie** $p_k = k$ (d.h. keine\n",
    "Zeilenvertauschungen) ist nur dann anwendbar und numerisch stabil, wenn\n",
    "$A$ wenigstens **schwach diagonaldominant** ist:\n",
    "\n",
    "[\\[defi:diagonaldominant\\]]{#defi:diagonaldominant\n",
    "label=\"defi:diagonaldominant\"}\n",
    "\n",
    "a)  $A\\in\\mathbb{R}^{n\\times n}$ heißt **strikt diagonaldominant**, falls\n",
    "    $$|a_{ii}| > \\sum_{\\substack{k=1\\\\k\\neq i}}^n |a_{ik}|, \\quad i=1,2,\\ldots n.$$\n",
    "\n",
    "b)  $A$ heißt **schwach diagonaldominant**, falls oben für\n",
    "    mindestens einen Index $i$ die strenge Ungleichung $>$ gilt und für\n",
    "    die übrigen $\\geqslant$.\n",
    "\n",
    "[<img src=\"figs/tafel.png\" alt=\"Tafel\"\n",
    "\ttitle=\"Beispiel\" width=\"50\" height=\"50\" />](../Numerik/AufschriebeNeu/Numerik%203.pdf)\n",
    "\n",
    "Zur Vermeidung von Rundungsfehlern nimmt man am besten das betragsmäßig\n",
    "größte Element einer Spalte als Pivot: **Spaltenmaximumstrategie**\n",
    "$$\\max_{k\\leqslant i\\leqslant n} |a_{ik}^{(k-1)}| = |a_{p_k k}^{(k-1)}|$$\n",
    "\n",
    "Noch stabiler ist die **relative Spaltenmaximumstrategie**, wobei\n",
    "man dasjenige Element einer Spalte als Pivot nimmt, das betragsmäßig\n",
    "relativ zur Summe der Beträge der Elemente der zugehörigen Zeile am\n",
    "größten ist:\n",
    "$$\\max_{k\\leqslant i\\leqslant n} \\frac{|a_{ik}^{(k-1)}|}{\\sum_{j=k}^n |a_{ij}^{(k-1)}|} = \\frac{|a_{p_k k}^{(k-1)}|}{\\sum_{j=k}^n |a_{p_k j}^{(k-1)}|}$$\n",
    "\n",
    "[<img src=\"figs/notebook.png\" alt=\"Notebook\"\n",
    "\ttitle=\"Beispiel\" width=\"50\" height=\"50\" />](../Numerik/Python/chapter3.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d3b6c0",
   "metadata": {},
   "source": [
    "Lineare Gleichungssysteme:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e93b48",
   "metadata": {},
   "source": [
    "Der Gauß-Algorithmus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e99a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backsubst(U, y, p):\n",
    "    \"\"\"Rücksubstitution: Berechnet aus der rechten oberen Dreiecksmatrix U und rechten Seite y die Lösung x und rundet dabei auf p signifikante Dezimalstellen.\"\"\"\n",
    "    n = len(y)  #Indizes 0,1,...,n-1\n",
    "    if not np.shape(U) == (n,n):\n",
    "        raise Exception(\"Dimensionen von U und y passen nicht\")\n",
    "    x = np.zeros(n)\n",
    "    for i in range(n-1, -1, -1):\n",
    "        x[i] = y[i]\n",
    "        for k in range(i+1, n):\n",
    "            x[i] = signif(x[i] - signif(U[i,k]*x[k], p), p)\n",
    "        x[i] = signif(x[i]/U[i,i], p)\n",
    "    return np.array([x]).T  #Spaltenvektor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f246df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forwsubst(L, b, p):\n",
    "    \"\"\"Vorwärtssubstitution: Berechnet aus der linken unteren Dreiecksmatrix L mit Einsen auf der Diagonale und der rechten Seite b die Zwischenlösung y.\"\"\"\n",
    "    n = len(b)  #Indizes 0,1,...,n-1\n",
    "    if not np.shape(L) == (n,n):\n",
    "        raise Exception(\"Dimensionen von L und b passen nicht\")\n",
    "    y = np.zeros(n)\n",
    "    for i in range(1, n):\n",
    "        y[i] = b[i]\n",
    "        for j in range(0, i):\n",
    "            y[i] = signif(y[i] - signif(L[i,j]*y[j], p), p)\n",
    "        y[i] = signif(y[i]/L[i,i], p)\n",
    "    return np.array([y]).T  #Spaltenvektor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8def23",
   "metadata": {},
   "source": [
    "Beispiel zum Gauß'schen Eliminationsverfahren:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a8d437",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "A = np.array([[2.1, 2512, -2516], [-1.3, 8.8, -7.6], [0.9, -6.2, 4.6]])\n",
    "b = np.array([[6.5], [-5.3], [2.9]])\n",
    "Ab = np.concatenate((A, b), axis=1)\n",
    "print(\"Erweiterte Koeffizientenmatrix Ab = \\n {} \\n\".format(np.matrix(Ab)))\n",
    "print()\n",
    "\n",
    "x_exakt = np.array([[5], [1], [1]])\n",
    "print(\"A*x_exakt - b = \\n {} \\n\".format(np.matmul(A, x_exakt) - b))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bdf4054",
   "metadata": {},
   "source": [
    "Wir probieren verschiedene Pivotstrategien aus und runden dabei auf $p$ Dezimalstellen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fcc1072",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2a19a3",
   "metadata": {},
   "source": [
    "Spaltenmaximumstrategie:\n",
    "In diesem Fall identisch mit der Diagonalstrategie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c392b0fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Erster Eliminationsschritt\n",
    "Ab1 = np.zeros((3,4))\n",
    "Ab1[0,:] = Ab[0,:]\n",
    "l10 = signif(Ab[1,0]/Ab[0,0], p)\n",
    "l20 = signif(Ab[2,0]/Ab[0,0], p)\n",
    "Ab1[1,1:] = signif(Ab[1,1:] - signif(l10*Ab[0,1:], p), p)\n",
    "Ab1[2,1:] = signif(Ab[2,1:] - signif(l20*Ab[0,1:], p), p)\n",
    "print(\"Ab1 = \\n {} \\n\".format(np.matrix(Ab1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77dd05b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Zweiter Eliminationsschritt\n",
    "Ab2 = np.zeros((3,4))\n",
    "Ab2[[0,1],:] = Ab1[[0,1],:]\n",
    "l21 = signif(Ab1[2,1]/Ab1[1,1], p)\n",
    "Ab2[2,2:] = signif(Ab1[2,2:] - signif(l21*Ab1[1,2:], p), p)\n",
    "print(\"Ab2 = \\n {} \\n\".format(np.matrix(Ab2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250a9303",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Wir speichern die LU-Zerlegung für später\n",
    "U = Ab2[0:3,0:3]\n",
    "L = np.array([[1, 0, 0], [l10, 1, 0], [l20, l21, 1]])\n",
    "\n",
    "#Rücksubstitution\n",
    "x_spmax = backsubst(Ab2[:,0:3], Ab2[:,3], p)\n",
    "print(\"x = \\n {} \\n\".format(x_spmax))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56acd9ce",
   "metadata": {},
   "source": [
    "Relative Spaltenmaximumstrategie:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebad9118",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Bestimme Quotienten aus Elementen der Spalte 0 und Betragssumme der jeweiligen Zeile\n",
    "q = [abs(Ab[i,0])/np.sum(abs(Ab[i,0:3])) for i in range(0,3)]\n",
    "print(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d531cf1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Vertausche Zeilen \n",
    "Ab1 = Ab[[2,1,0],:]\n",
    "print(\"Ab1 = \\n {} \\n\".format(Ab1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020beea1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Erster Eliminationsschritt\n",
    "Ab2 = np.zeros((3,4))\n",
    "Ab2[0,:] = Ab1[0,:]\n",
    "l10 = signif(Ab1[1,0]/Ab1[0,0], p)\n",
    "l20 = signif(Ab1[2,0]/Ab1[0,0], p)\n",
    "Ab2[1,1:] = signif(Ab1[1,1:] - l10*Ab1[0,1:], p)\n",
    "Ab2[2,1:] = signif(Ab1[2,1:] - l20*Ab1[0,1:], p)\n",
    "print(\"Ab2 = \\n {} \\n\".format(np.matrix(Ab2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32736125",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Bestimme Quotienten aus Elementen der Spalte 1 und Betragssumme der jeweiligen Zeile\n",
    "q = [abs(Ab2[i,1])/np.sum(abs(Ab2[i,1:3])) for i in range(1,3)] \n",
    "print(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ef4cca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Vertausche Zeilen \n",
    "Ab3 = Ab2[[0,2,1], :]\n",
    "print(\"Ab3 = \\n {} \\n\".format(Ab3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e0c409",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Zweiter Eliminationsschritt\n",
    "Ab4 = np.zeros((3,4))\n",
    "Ab4[[0,1],:] = Ab3[[0,1],:]\n",
    "l21 = signif(Ab3[2,1]/Ab3[1,1], p)\n",
    "Ab4[2,2:] = signif(Ab3[2,2:] - signif(l21*Ab3[1,2:], p), p)\n",
    "print(\"Ab4 = \\n {} \\n\".format(np.matrix(Ab4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c2352a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Rücksubstitution\n",
    "x_relspmax = backsubst(Ab4[:,0:3], Ab4[:,3], p)\n",
    "print(\"x = \\n {} \\n\".format(x_relspmax))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5373e85c",
   "metadata": {},
   "source": [
    "Deutlich genaueres Ergebnis als mit Spaltenmaximumstrategie!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da675be1",
   "metadata": {},
   "source": [
    "#### Nachiteration\n",
    "\n",
    "-   Hat man eine numerische Lösung $\\tilde x$ des LGS $Ax=b$ gefunden,\n",
    "    sollte man die Einsetzprobe machen, indem man den\n",
    "    **Residuenvektor** bildet: $$r := A\\tilde x - b.$$\n",
    "\n",
    "-   Eine verbesserte Lösung $x$ kann man erhalten, indem man den\n",
    "    Korrekturansatz $$x = \\tilde x + z$$ macht und $z$ so bestimmt, dass\n",
    "    $x$ das LGS löst:\n",
    "    $$0 = Ax - b = A(\\tilde x + z) - b = A\\tilde x + A z - b = Az + r$$\n",
    "\n",
    "-   Man muss also folgendes LGS nach $z$ lösen: $$Az = -r$$\n",
    "\n",
    "-   Hat man bereits die LU-Zerlegung von $A$, muss nur die Vor- und\n",
    "    Rückwärtssubstitution nochmal ausgeführt werden.\n",
    "\n",
    "<img src=\"figs/notebook.png\" alt=\"Notebook\"\n",
    "\ttitle=\"Beispiel\" width=\"50\" height=\"50\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519222d4",
   "metadata": {},
   "source": [
    "### Komplexität\n",
    "\n",
    "Als **Komplexität** eines Algorithmus bezeichnet man die Anzahl\n",
    "der benötigten elementaren Rechenoperationen.\\\n",
    "Ist $A\\in\\mathbb{R}^{n\\times n}$, so ist der Aufwand für große $n$\n",
    "besonders wichtig, d.h. uns interessiert v.a. der führende Term bzgl.\n",
    "$n$.\n",
    "\n",
    "a)  Seien $(a_n)$ und $(b_n)$ Folgen. Man schreibt\n",
    "    $a_n \\in \\mathcal{O}(b_n)$, falls\n",
    "    $$\\limsup_{ n\\to\\infty}  \\left| \\frac{a_n}{b_n} \\right| < \\infty.$$\n",
    "\n",
    "b)  Seien $f$ und $g$ reelle Funktionen und\n",
    "    $a\\in\\mathbb{R}\\cup\\{-\\infty, +\\infty\\}$.\\\n",
    "    Man schreibt $f\\in\\mathcal{O}(g)$, falls\n",
    "    $\\displaystyle \\limsup_{x\\to a} \\left| \\frac{f(x)}{g(x)} \\right| < \\infty$.\n",
    "\n",
    "Beispiel: $n^3 - 2n^2 + 1 \\in \\mathcal{O}(n^3)$.\n",
    "\n",
    "### Komplexität\n",
    "\n",
    "Zu lösen ist das LGS $Ax = b$ mit\n",
    "$A = (a_{ij}) \\in \\mathbb{R}^{n\\times n}$ regulär,\n",
    "$b = (b_i) \\in \\mathbb{R}^n$.\n",
    "\n",
    "a)  Die Komplexität der Gauß-Elimination/LU-Zerlegung ist\n",
    "    $\\mathcal{O}(n^3)$.\n",
    "\n",
    "b)  Die Komplexität der Vorwärtssubstitution ist $\\mathcal{O}(n^2)$.\n",
    "\n",
    "c)  Die Komplexität der Rückwärtssubstitution ist $\\mathcal{O}(n^2)$.\n",
    "\n",
    "![image](figs/tafel.png){width=\"0.5cm\"}Beweis\\\n",
    "Möchte man das LGS für viele rechte Seiten $b$ bei gleicher Matrix $A$\n",
    "lösen, so braucht man die LU-Zerlegung nur einmal berechnen.\\\n",
    "Die Vorwärts- und Rückwärtssubstitution gehen viel schneller!\n",
    "\n",
    "Spezialfall: Bandmatrizen {#s:bandmatrizen}\n",
    "-------------------------\n",
    "\n",
    "Bei einer **Bandmatrix** $A$ liegen alle von Null verschiedenen\n",
    "Elemente $a_{ij}$ in der Diagonale und einigen benachbarten\n",
    "Nebendiagonalen.\\\n",
    "**Anwendungen:**\n",
    "\n",
    "-   Splines (Kapitel 5)\n",
    "\n",
    "-   Diskretisierung von Differentialgleichungen mit finiten Differenzen\n",
    "    (Kapitel 6)\n",
    "\n",
    "Einfachster Fall: **Tridiagonale Matrix**\n",
    "$$A = \\left( \\begin{array}{ccccc}\n",
    "    a_1 & b_1 & & & \\\\\n",
    "    c_2 & a_2 & b_2 & & \\\\\n",
    "    & \\ddots & \\ddots & \\ddots & \\\\\n",
    "    & & c_{n-1} & a_{n-1} & b_{n-1} \\\\\n",
    "    & & & c_n & a_n             \n",
    "    \\end{array} \\right)$$ Die LU-Zerlegung hat nun die Form\n",
    "$$L = \\left( \\begin{array}{cccc}\n",
    "    1 & & & \\\\ l_1 & 1 & & \\\\ & \\ddots & \\ddots & \\\\ & & l_{n-1} & 1\n",
    "    \\end{array} \\right), \\quad \n",
    "    U = \\left( \\begin{array}{cccc}\n",
    "    m_1 & r_1 & & \\\\ & \\ddots & \\ddots & \\\\ & & m_{n-1} & r_{n-1} \\\\ \n",
    "    & & & m_n\n",
    "    \\end{array} \\right)$$\n",
    "\n",
    "[\\[algo:thomas\\]]{#algo:thomas label=\"algo:thomas\"} Das LGS $Ax = d$ mit\n",
    "obiger Tridiagonalmatrix $A$ löst man wie folgt:\n",
    "\n",
    "1.  LU-Zerlegung: $$\\begin{aligned}\n",
    "              & m_1 = a_1\\\\\n",
    "              & \\text{Für } i=1,\\ldots, n-1:\\\\\n",
    "              & \\qquad l_i = c_{i+1}/m_i\\\\\n",
    "              & \\qquad m_{i+1} = a_{i+1} - l_i b_i\n",
    "            \\end{aligned}$$\n",
    "\n",
    "2.  Vorwärtssubstitution $Ly = d$: $$\\begin{aligned}\n",
    "              & y_1 = d_1\\\\\n",
    "              & \\text{Für } i=2, \\ldots, n:\\\\\n",
    "              & \\qquad y_i = d_i - l_{i-1} y_{i-1}\n",
    "            \\end{aligned}$$\n",
    "\n",
    "3.  Rückwärtssubstitution $Ux = y$: $$\\begin{aligned}\n",
    "              & x_n = y_n / m_n\\\\\n",
    "              & \\text{Für } i=n-1,\\ldots, 1:\\\\\n",
    "              & \\qquad x_i = (y_i - b_i x_{i+1})/m_i\n",
    "            \\end{aligned}$$\n",
    "\n",
    "![image](figs/tafel.png){width=\"0.5cm\"}Herleitung des\n",
    "Thomas-Algorithmus\\\n",
    "![image](figs/notebook.png){width=\"0.5cm\"}Implementierung, Beispiel\\"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a6f5ba",
   "metadata": {},
   "source": [
    "Die Komplexität des Thomas-Algorithmus ist $\\mathcal{O}(n)$.\n",
    "\n",
    "Man vergleiche dies mit der Komplexität $\\mathcal{O}(n^3)$ der\n",
    "Gauß-Elimination für allgemeine Matrizen!\n",
    "\n",
    "Fehlerabschätzung, Kondition\n",
    "----------------------------\n",
    "\n",
    "Wir wollen den Fehler der numerischen Lösung eines LGS abschätzen. Dazu\n",
    "benötigen wir Maßzahlen für Vektoren und Matrizen. Analog zur Vektornorm\n",
    "definieren wir\n",
    "\n",
    "Eine Matrixnorm $\\lVert {A} \\rVert$ einer Matrix\n",
    "$A\\in\\mathbb{R}^{n\\times n}$ ist eine reelle Funktion ihrer Elemente mit\n",
    "folgenden Eigenschaften:\n",
    "\n",
    "a)  $\\lVert {A} \\rVert \\geqslant 0$ für alle\n",
    "    $A \\in\\mathbb{R}^{n\\times n}$, und\n",
    "    $\\lVert {A} \\rVert = 0 \\Leftrightarrow A = 0$\n",
    "\n",
    "b)  $\\lVert {cA} \\rVert = |c| \\cdot \\lVert {A} \\rVert$ für alle\n",
    "    $c\\in\\mathbb{R}$ und alle $A\\in\\mathbb{R}^{n\\times n}$\n",
    "\n",
    "c)  $\\lVert {A+B} \\rVert \\leqslant \\lVert {A} \\rVert + \\lVert {B} \\rVert$\n",
    "    für alle $A,B\\in\\mathbb{R}^{n\\times n}$ (Dreiecksungleichung)\n",
    "\n",
    "d)  $\\lVert {A\\cdot B} \\rVert \\leqslant \\lVert {A} \\rVert \\cdot \\lVert {B} \\rVert$\n",
    "    (Submultiplikativität)\n",
    "\n",
    "### Beispiele für Matrixnormen\n",
    "\n",
    "$$\\begin{aligned}\n",
    "     \\lVert {A} \\rVert_G &:=& n \\cdot \\max_{i,k=1}^n |a_{ik}| \\qquad \\text{Gesamtnorm}\\\\\n",
    "     \\lVert {A} \\rVert_Z &:=& \\max_{i=1}^n \\sum_{k=1}^n |a_{ik}| \\qquad \\text{Zeilensummennorm}\\\\\n",
    "     \\lVert {A} \\rVert_S &:=& \\max_{k=1}^n \\sum_{i=1}^n |a_{ik}| \\qquad \\text{Spaltensummennorm}\\\\\n",
    "     \\lVert {A} \\rVert_F &:=& \\left( \\sum_{i,k=1}^n a_{ik}^2 \\right)^{\\tfrac{1}{2}} \\qquad \\text{Frobenius-Norm}\n",
    "  \\end{aligned}$$ Wie alle Vektornormen sind auch alle Matrixnormen\n",
    "miteinander äquivalent, d.h. für je zwei Matrixnormen\n",
    "$\\lVert {\\cdot} \\rVert_1$ und $\\lVert {\\cdot} \\rVert_2$ gibt es\n",
    "Konstanten $\\alpha,\\beta>0$ mit\n",
    "$\\alpha \\lVert {A} \\rVert_1 \\leqslant \\lVert {A} \\rVert_2 \\leqslant \\beta \\lVert {A} \\rVert_1$\n",
    "für alle $A\\in\\mathbb{R}^{n\\times n}$.\n",
    "\n",
    "Eine Matrixnorm $\\lVert {A} \\rVert$ heißt **kompatibel** oder\n",
    "**verträglich** mit der Vektornorm $\\lVert {x} \\rVert$, falls\n",
    "gilt:\n",
    "$$\\lVert {Ax} \\rVert \\leqslant \\lVert {A} \\rVert \\, \\lVert {x} \\rVert \\text{ für alle } x\\in\\mathbb{R}^n \\text{ und alle } A\\in\\mathbb{R}^{n\\times n}.$$\n",
    "\n",
    "![image](figs/tafel.png){width=\"0.5cm\"}Beispiel\n",
    "\n",
    "[\\[defi:zugeordnete_matrixnorm\\]]{#defi:zugeordnete_matrixnorm\n",
    "label=\"defi:zugeordnete_matrixnorm\"} Zu einer gegebenen Vektornorm\n",
    "definiert man die **zugeordnete** oder **natürliche**\n",
    "Matrixnorm\n",
    "$$\\lVert {A} \\rVert := \\max_{x\\neq 0} \\frac{\\lVert {Ax} \\rVert}{\\lVert {x} \\rVert} = \\max_{\\lVert {x} \\rVert = 1} \\lVert {Ax} \\rVert.$$\n",
    "\n",
    "![image](figs/tafel.png){width=\"0.5cm\"}Beispiele\n",
    "\n",
    "Die zugeordnete Matrixnorm aus Definition\n",
    "[\\[defi:zugeordnete_matrixnorm\\]](#defi:zugeordnete_matrixnorm){reference-type=\"ref\"\n",
    "reference=\"defi:zugeordnete_matrixnorm\"} erfüllt alle Eigenschaften\n",
    "einer Matrixnorm. Sie ist mit der zu Grunde liegenden Vektornorm\n",
    "kompatibel und ist unter allen mit dieser Vektornorm kompatiblen\n",
    "Matrixnormen die kleinste.\n",
    "\n",
    "Welche Rückschlüsse kann man aus der Größe des Residuums\n",
    "$r=A\\tilde x - b$ einer numerischen Lösung $\\tilde x$ auf den Fehler\n",
    "$z:=x - \\tilde x$ bzgl. der exakten Lösung $x$ ziehen?\n",
    "\n",
    "$$\\frac{\\lVert {z} \\rVert}{\\lVert {x} \\rVert} \\leqslant \\lVert {A} \\rVert \\lVert {A^{-1}} \\rVert \\frac{\\lVert {r} \\rVert}{\\lVert {b} \\rVert} =: \\kappa(A) \\frac{\\lVert {r} \\rVert}{\\lVert {b} \\rVert}$$\n",
    "für beliebige verträgliche Normen, wobei $\\kappa(A) \\geqslant 1$.\n",
    "\n",
    "![image](figs/tafel.png){width=\"0.5cm\"}Beweis\n",
    "\n",
    "$\\kappa(A) := \\lVert {A} \\rVert \\lVert {A^{-1}} \\rVert$ heißt\n",
    "**Konditionszahl** der Matrix $A$. Sie ist abhängig von der\n",
    "verwendeten Matrixnorm.\n",
    "\n",
    "Kleines Residuum $\\Rightarrow$ kleiner Fehler nur, falls Konditionszahl\n",
    "klein!\\\n",
    "Für $\\kappa(A)\\gg 1$ ist das LGS **schlecht konditioniert**.\n",
    "\n",
    "Welchen Einfluss haben Fehler in den Koeffizienten von $A$ und $b$ auf\n",
    "die Lösung $x$?\n",
    "\n",
    "Die Matrix $A$ werde um $\\delta A$ und die rechte Seite $b$ um\n",
    "$\\delta b$ geändert. Dann gilt für die Änderung $\\delta x$ der Lösung\n",
    "$x$:\n",
    "$$\\frac{\\lVert {\\delta x} \\rVert}{\\lVert {x} \\rVert} \\leqslant \\frac{\\kappa(A)}{1 - \\kappa(A) \\frac{\\lVert {\\delta A} \\rVert}{\\lVert {A} \\rVert}} \\left( \\frac{\\lVert {\\delta A} \\rVert}{\\lVert {A} \\rVert} + \\frac{\\lVert {\\delta b} \\rVert}{\\lVert {b} \\rVert} \\right)$$\n",
    "für beliebige verträgliche Normen.\n",
    "\n",
    "![image](figs/tafel.png){width=\"0.5cm\"}Beweis, Beispiel\n",
    "\n",
    "Daumenregeln\n",
    "\n",
    "-   Wird ein LGS $Ax=b$ mit auf $d$ Dezimalstellen genauer\n",
    "    Gleitpunktrechnung gelöst und ist $\\kappa(A) \\approx 10^\\alpha$, so\n",
    "    sind in der betragsgrößten Komponente der Lösung $\\tilde x$ nur\n",
    "    $d-\\alpha-1$ Dezimalstellen sicher.\n",
    "\n",
    "-   Strikt diagonaldominante Matrizen sind gut konditioniert.\n",
    "\n",
    "Nichtlineare Gleichungen\n",
    "========================\n",
    "\n",
    "### Lösung nichtlinearer Geichungen\n",
    "\n",
    "-   Wir suchen eine Nullstelle einer reellen Funktion\n",
    "    $f:[a,b]\\to\\mathbb{R}$:\n",
    "    $$\\text{Finde } x_*\\in[a,b] \\text{ mit } f(x_*) = 0.$$\n",
    "\n",
    "-   Es kann mehrere Lösungen geben!\n",
    "\n",
    "-   Numerische Lösungsverfahren sind meistens **iterativ**, d.h.\n",
    "    sie konstruieren eine Folge von Approximationen\n",
    "    $(x_k)_{k\\in\\mathbb{N}}$ ausgehend von einem Startwert $x_0$, so\n",
    "    dass idealerweise $\\lim_{k\\to\\infty} x_k = x_*$.\n",
    "\n",
    "-   Für eine schlechte Wahl des Startwerts $x_0$ kann $(x_k)$ u.U.\n",
    "    divergieren, obwohl es eine Nullstelle $x_*$ gibt.\n",
    "\n",
    "-   Falls es mehrere Lösungen gibt, so hängt es von $x_0$ ab, gegen\n",
    "    welche $(x_k)$ konvergiert. *Alle* Lösungen zu finden ist oft\n",
    "    schwierig.\n",
    "\n",
    "[\\[defi:konvergenzgeschw\\]]{#defi:konvergenzgeschw\n",
    "label=\"defi:konvergenzgeschw\"}\n",
    "\n",
    "a)  Eine Folge $(x_k)$ mit Grenzwert $x_*$ hat (mindestens) die\n",
    "    **Konvergenzordnung** $p\\geqslant 1$, wenn es eine von $k$\n",
    "    unabhängige Konstante $C>0$ gibt, so dass\n",
    "    $$|x_{k+1} - x_*| \\leqslant C |x_k - x_*|^p \\quad \\forall \\, k\\in\\mathbb{N}_0.$$\n",
    "    $C$ heißt **Konvergenzrate**.\n",
    "\n",
    "b)  Für $p=1$ spricht man von **(Q-)linearer** Konvergenz. In dem\n",
    "    Fall muss $C<1$ sein.\n",
    "\n",
    "c)  $(x_k)$ heißt **R-linear** konvergent, falls es eine Q-linear\n",
    "    konvergente Nullfolge $(\\alpha_k) \\subset (0,\\infty)$ gibt, so dass\n",
    "    $$|x_k - x_*|\\leqslant \\alpha_k \\quad \\forall \\, k\\in\\mathbb{N}_0.$$\n",
    "\n",
    "-   Je größer die Konvergenzordnung $p$, desto schneller konvergiert das\n",
    "    Verfahren.\n",
    "\n",
    "-   Ein Vergleich der Konvergenzrate $C$ ist nur bei Verfahren gleicher\n",
    "    Konvergenzordnung wichtig.\n",
    "\n",
    "Bisektionsverfahren\n",
    "-------------------\n",
    "\n",
    "Sei $f:[a,b]\\to\\mathbb{R}$ stetig. Ist $f(a) f(b) < 0$, so hat $f$\n",
    "(mindestens) eine Nullstelle in $[a,b]$.\n",
    "\n",
    "Der Beweis beruht auf dem folgenden Algorithmus:\n",
    "\n",
    "Überprüfe $f(a)f(b)<0$, setze $a_0 := a$, $b_0 := b$\\\n",
    "Für $k=0,1,2,\\ldots$:\\\n",
    "$\\qquad x_k := {\\textstyle \\frac{1}{2}}(a_k + b_k)$\\\n",
    "$\\qquad$ Falls $f(a_k) f(x_k) > 0$, setze $a_{k+1} := x_k$,\n",
    "$b_{k+1} := b_k$,\\\n",
    "$\\qquad$ andernfalls $a_{k+1} := a_k$, $b_{k+1} := x_k$\\\n",
    "solange bis Abbruchkriterium erfüllt, z.B. $|f(x_k)| < \\varepsilon$ oder\n",
    "$b_k - a_k < \\delta$\n",
    "\n",
    "![image](figs/notebook.png){width=\"0.5cm\"}Implementierung, Beispiel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8576914f",
   "metadata": {},
   "source": [
    "Unter den Voraussetzungen des Nullstellensatzes konvergiert die Folge\n",
    "der Intervallmitten $(x_k)$ gegen eine Nullstelle $x_*$ von $f$,\\\n",
    "und es gilt die *a priori* Fehlerabschätzung\n",
    "$$|x_k  - x_*| \\leqslant \\frac{b-a}{2^{k+1}}, \\quad k=0,1,2,\\ldots$$ Das\n",
    "Bisektionsverfahren konvergiert also R-linear.\n",
    "\n",
    "![image](figs/tafel.png){width=\"0.5cm\"}Beweis\\\n",
    "Die Konvergenz muss nicht monoton sein: i.A.\n",
    "$|x_{k+1}  - x_*| \\nleqslant |x_k  - x_*|$.\n",
    "\n",
    "Newton-Verfahren\n",
    "----------------\n",
    "\n",
    "Angenommen, $f:[a,b]\\to\\mathbb{R}$ ist differenzierbar und die Ableitung\n",
    "$f'$ lässt sich leicht  berechnen.\\\n",
    "Beim Newton-Verfahren ersetzt man die Funktion $f$ durch die Tangente im\n",
    "Punkt $(x_k, f(x_k))$, um die nächste Näherung $x_{k+1}$ zu bestimmen.\\\n",
    "![image](figs/tafel.png){width=\"0.5cm\"}Skizze, Herleitung\n",
    "\n",
    "[\\[a:newton\\]]{#a:newton label=\"a:newton\"} Wähle $x_0\\in[a,b]$ mit\n",
    "$f'(x_0) \\neq 0$\\\n",
    "Für $k=0,1,2,\\ldots$:\\\n",
    "$\\qquad$ $x_{k+1} := x_k - \\dfrac{f(x_k)}{f'(x_k)} =: x_k - \\Delta x_k$\\\n",
    "solange bis Abbruchkriterium erfüllt, z.B. $|\\Delta x_k| < \\delta$ oder\n",
    "$|f(x_k)| < \\varepsilon$\n",
    "\n",
    "![image](figs/notebook.png){width=\"0.5cm\"}Implementierung, Beispiel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d640e37",
   "metadata": {},
   "source": [
    "### Anwendung: Heron-Verfahren\n",
    "\n",
    "-   Zur Berechnung von $\\sqrt{a}$ suchen wir die Nullstelle der Funktion\n",
    "    $$f:(0,\\infty)\\to\\mathbb{R}, \\quad f(x) = x^2 - a, \\qquad f'(x) = 2x$$\n",
    "\n",
    "-   Das Newton-Verfahren lautet\n",
    "    $$x_{k+1} = x_k - \\frac{f(x_k)}{f'(x_k)} = x_k - \\frac{x_k^2 - a}{2x_k} = \\frac{1}{2}\\left( x_k + \\frac{a}{x_k}\\right).$$\n",
    "\n",
    "-   Dieses Verfahren wurde nach Heron von Alexandria (100 n. Chr.)\n",
    "    benannt, war aber bereits um 1750 v. Chr. in Mesopotamien bekannt.\n",
    "\n",
    "![image](figs/notebook.png){width=\"0.5cm\"}Implementierung"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6981b3",
   "metadata": {},
   "source": [
    "[\\[s:newtonkonv\\]]{#s:newtonkonv label=\"s:newtonkonv\"} Sei\n",
    "$f\\in C^2([a,b])$ und $x_*\\in(a,b)$ mit $f(x_*)=0$ und $f'(x_*)\\neq 0$.\\\n",
    "Dann gibt es ein $\\delta>0$, so dass das Newton-Verfahren für jeden\n",
    "Startwert $x_0\\in(x_*-\\delta, x_*+\\delta)$ **quadratisch** gegen\n",
    "$x_*$ konvergiert,\\\n",
    "d.h. $p=2$ in Def.\n",
    "[\\[defi:konvergenzgeschw\\]](#defi:konvergenzgeschw){reference-type=\"ref\"\n",
    "reference=\"defi:konvergenzgeschw\"}.\n",
    "\n",
    "![image](figs/tafel.png){width=\"0.5cm\"}Beweis\n",
    "\n",
    "### Komplikationen beim Newton-Verfahren\n",
    "\n",
    "-   Das Verfahren kann scheitern, wenn ein Folgenglied $x_k$ nicht mehr\n",
    "    im (maximalen) Definitionsbereich von $f$ liegt.\n",
    "\n",
    "-   $(x_k)$ kann divergieren, obwohl Nullstellen existieren.\n",
    "\n",
    "-   Die Rekursion kann endlos zwischen zwei Werten hin und her pendeln.\n",
    "\n",
    "Beispiele siehe Übungen\n",
    "\n",
    "Falls die Berechnung der Ableitung aufwendig ist, kann man versuchen,\n",
    "dies nur einmal für den Startwert zu tun:\n",
    "\n",
    "Wähle $x_0\\in[a,b]$ mit $f'(x_0) \\neq 0$\\\n",
    "Für $k=0,1,2,\\ldots$:\\\n",
    "$\\qquad$ $x_{k+1} := x_k - \\dfrac{f(x_k)}{f'(x_0)} =: x_k - \\Delta x_k$\\\n",
    "solange bis Abbruchkriterium erfüllt, z.B. $|\\Delta x_k| < \\delta$ oder\n",
    "$|f(x_k)| < \\varepsilon$\n",
    "\n",
    "Das vereinfachte Newton-Verfahren konvergiert i.A. nur linear.\n",
    "\n",
    "Sekantenverfahren, Regula falsi\n",
    "-------------------------------\n",
    "\n",
    "Beim Sekantenverfahren erhält man die nächste Näherung $x_{k+1}$ als\n",
    "Nullstelle der Geraden (Sekanten) durch die Punkte $(x_k, f(x_k))$ und\n",
    "$(x_{k-1}, f(x_{k-1}))$. Es werden zwei Startwerte $x_0, x_1$ benötigt,\n",
    "die die gesuchte Nullstelle von $f$ nicht unbedingt einschließen\n",
    "müssen.\\\n",
    "![image](figs/tafel.png){width=\"0.5cm\"}Skizze, Herleitung\n",
    "\n",
    "Wähle $x_0, x_1 \\in[a,b]$\\\n",
    "Für $k=1,2,3,\\ldots$:\\\n",
    "$\\qquad$\n",
    "$x_{k+1} := x_k - f(x_k) \\dfrac{x_k - x_{k-1}}{f(x_k) - f(x_{k-1})} =: x_k - \\Delta x_k$\\\n",
    "solange bis Abbruchkriterium erfüllt, z.B. $|\\Delta x_k| < \\delta$ oder\n",
    "$|f(x_k)| < \\varepsilon$\n",
    "\n",
    "![image](figs/notebook.png){width=\"0.5cm\"}Implementierung, Beispiel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ea86b0",
   "metadata": {},
   "source": [
    "Vorteil des Sekantenverfahrens ggü. dem Newton-Verfahren:\\\n",
    "Die Ableitung von $f$ wird nicht benötigt.\\\n",
    "Nachteil: langsamere Konvergenz\n",
    "\n",
    "Falls $f'(x_*)\\neq 0$ und $f''(x_*)\\neq 0$, so ist die Konvergenzordnung\n",
    "des Sekantenverfahrens\n",
    "$$p = {\\textstyle \\frac{1}{2}}(1 + \\sqrt{5}) \\approx 1.618.$$\n",
    "\n",
    "Das Sekantenverfahren lässt sich mit dem Bisektionsverfahren\n",
    "kombinieren. So erhält man die **Regula falsi** (Regel des\n",
    "Falschen, schon $\\sim$ 1550 v. Chr. Ägypten, auch Adam Ries(e) $\\sim$\n",
    "1522 bekannt):\n",
    "\n",
    "Überprüfe $f(a)f(b)<0$, setze $a_0 := a$, $b_0 := b$\\\n",
    "Für $k=0,1,2,\\ldots$:\\\n",
    "$\\qquad x_k := a_k - f(a_k) \\dfrac{b_k - a_k}{f(b_k) - f(a_k)}$\\\n",
    "$\\qquad$ Falls $f(a_k) f(x_k) > 0$, setze $a_{k+1} := x_k$,\n",
    "$b_{k+1} := b_k$,\\\n",
    "$\\qquad$ andernfalls $a_{k+1} := a_k$, $b_{k+1} := x_k$\\\n",
    "solange bis Abbruchkriterium erfüllt, z.B. $|f(x_k)| < \\varepsilon$ oder\n",
    "$b_k - a_k < \\delta$\n",
    "\n",
    "**Beobachtung:** Ersetzt man in der Rekursion $f(a_k) \\to -1$ und\n",
    "$f(b_k)\\to 1$, so erhält man $x_k = (a_k + b_k)/2$, das\n",
    "Bisektionsverfahren.\n",
    "\n",
    "Skizze der ersten beiden Iterationen:\\\n",
    "![image](figs/False_position_method.png){height=\"0.7\\\\textheight\"}\\\n",
    "<https://commons.wikimedia.org/wiki/File:False_position_method.svg>\\\n",
    "![image](figs/notebook.png){width=\"0.5cm\"}Implementierung, Beispiel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c61c513",
   "metadata": {},
   "source": [
    "Fixpunktverfahren {#s:fixpunkt}\n",
    "-----------------\n",
    "\n",
    "**Idee:** Schreibe die nichtlineare Gleichung $$f(x) = 0, \\quad x\\in I$$\n",
    "als **Fixpunktgleichung** um: $$x = F(x), \\quad x\\in I$$ für eine\n",
    "geeignete Funktion $F$ und iteriere mit Startwert $x_0\\in I$:\n",
    "$$x_{k+1} = F(x_k), \\quad k = 0,1,2,\\ldots$$ Wann konvergiert $(x_k)$?\\\n",
    "![image](figs/notebook.png){width=\"0.5cm\"}Implementierung, Beispiel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08fe7971",
   "metadata": {},
   "source": [
    "a)  Eine reelle Funktion $f:I\\to\\mathbb{R}$ auf einem Intervall $I$\n",
    "    heißt **Lipschitz-stetig**, falls es eine Konstante $L>0$\n",
    "    gibt, so dass\n",
    "    $$|f(x_1) - f(x_2)| \\leqslant L \\, |x_1 - x_2| \\quad \\forall x_1, x_2 \\in I.$$\n",
    "\n",
    "b)  Ist $f:I\\to {I}$ Lipschitz-stetig mit $L<1$, so heißt $f$ eine\n",
    "    **Kontraktion**.\n",
    "\n",
    "```{=html}\n",
    "<!-- -->\n",
    "```\n",
    "a)  Ist $f:I\\to\\mathbb{R}$ Lipschitz-stetig, so ist $f$ auch stetig.\n",
    "\n",
    "b)  Ist $f:I\\to\\mathbb{R}$ differenzierbar und existiert\n",
    "    $$L := \\sup_{x\\in I} |f'(x)| < \\infty,$$ so ist $f$ auf $I$\n",
    "    Lipschitz-stetig mit Konstante $L$.\n",
    "\n",
    "Die Umkehrungen dieser Aussagen gelten i.A. nicht!\\\n",
    "![image](figs/tafel.png){width=\"0.5cm\"}Beweis, Beispiele\n",
    "\n",
    "[\\[satz:banach\\]]{#satz:banach label=\"satz:banach\"} Sei $F:I\\to I$ eine\n",
    "Kontraktion mit Lipschitz-Konstante $L<1$. Dann gilt:\n",
    "\n",
    "a)  Die Folge $(x_k)$ mit $x_{k+1} = F(x_k)$ konvergiert für jeden\n",
    "    Startwert $x_0\\in I$ gegen den eindeutigen Fixpunkt $x_*$ von $F$ in\n",
    "    $I$.\n",
    "\n",
    "b)  Es gilt die *a priori* Fehlerabschätzung\n",
    "    $$|x_k - x_*| \\leqslant \\frac{L^k}{1-L} |x_1 - x_0|, \\quad k=0,1,\\ldots$$\n",
    "\n",
    "c)  Es gilt die *a posteriori* Fehlerabschätzung\n",
    "    $$|x_k - x_*| \\leqslant \\frac{L}{1-L} |x_k - x_{k-1}|, \\quad k=1,2,\\ldots$$\n",
    "\n",
    "![image](figs/tafel.png){width=\"0.5cm\"}Beweis\n",
    "\n",
    "Als Folgerung und Verallgemeinerung erhalten wir:\n",
    "\n",
    "[\\[s:fpkonv\\]]{#s:fpkonv label=\"s:fpkonv\"} $F\\in C^{p+1}(I, I)$ habe\n",
    "einen Fixpunkt $x_* \\in I$.\n",
    "\n",
    "a)  Das Fixpunktverfahren ist mindestens linear konvergent, falls\n",
    "    $$|F'(x_*)|  < 1.$$\n",
    "\n",
    "b)  Das Fixpunktverfahren ist mindestens $p$-ter Ordnung,\n",
    "    $p\\geqslant 2$, falls\n",
    "    $$F^{(k)}(x_*) = 0 \\text{ für } k=1,2,\\ldots, p-1.$$\n",
    "\n",
    "c)  Das Fixpunktverfahren divergiert, falls $$|F'(x_*)|  > 1.$$\n",
    "\n",
    "**Bemerkung**: Für $|F'(x_*)|=1$ ist keine Aussage möglich.\\\n",
    "![image](figs/tafel.png){width=\"0.5cm\"}Beweis von a) und c)\n",
    "\n",
    "### Beispiel zur Fixpunktiteration\n",
    "\n",
    "-   **Logistische Gleichung** als demographisches Modell\\\n",
    "    (z.B. Virusausbreitung, $x$ Zahl der Infizierten)\n",
    "    $$x_{k+1} = F(x_k), \\qquad F(x) := \\alpha x (1 - x)$$\n",
    "\n",
    "-   Fixpunkt:\n",
    "    $$x_* = F(x_*) \\; \\Leftrightarrow \\; x_* = 1 - \\frac{1}{\\alpha}$$\n",
    "\n",
    "-   Ableitung:\n",
    "    $$F'(x) = \\alpha(1 - 2x) \\; \\Rightarrow \\; F'(x_*) = 2 - \\alpha$$\n",
    "\n",
    "-   Konvergenz für\n",
    "    $$|F'(x_*)| < 1 \\; \\Leftrightarrow \\; 1 < \\alpha < 3$$\n",
    "\n",
    "-   Divergenz für\n",
    "    $$|F'(x_*)| > 1 \\; \\Leftrightarrow \\; \\alpha < 1 \\, \\vee \\, \\alpha > 3$$\n",
    "\n",
    "### Beispiel zur Fixpunktiteration\n",
    "\n",
    "$0 < F'(x) < 1$: monotone Konvergenz, z.B. für $\\alpha = 1.9$\n",
    "![image](figs/fp1.png){height=\"0.75\\\\textheight\"}\\\n",
    "<https://www5.in.tum.de/lehre/vorlesungen/konkr_math/SS_14/vorl/vorl9_Fixpunktiteration.pdf>\n",
    "\n",
    "### Beispiel zur Fixpunktiteration\n",
    "\n",
    "$-1 < F'(x) < 0$: alternierende Konvergenz, z.B. für $\\alpha = 2.9$\n",
    "![image](figs/fp2.png){height=\"0.75\\\\textheight\"}\\\n",
    "<https://www5.in.tum.de/lehre/vorlesungen/konkr_math/SS_14/vorl/vorl9_Fixpunktiteration.pdf>\n",
    "\n",
    "### Beispiel zur Fixpunktiteration\n",
    "\n",
    "$|F'(x)| > 1$: Divergenz, z.B. für $\\alpha = 4$\n",
    "![image](figs/fp3.png){height=\"0.75\\\\textheight\"}\\\n",
    "<https://www5.in.tum.de/lehre/vorlesungen/konkr_math/SS_14/vorl/vorl9_Fixpunktiteration.pdf>\n",
    "\n",
    "### Das Newton-Verfahren als Fixpunktverfahren\n",
    "\n",
    "Das Newton-Verfahren (Algorithmus\n",
    "[\\[a:newton\\]](#a:newton){reference-type=\"ref\" reference=\"a:newton\"})\n",
    "zur Bestimmung einer Nullstelle einer differenzierbaren Funktion\n",
    "$f:[a,b]\\to\\mathbb{R}$ lässt sich als Fixpunktiteration\n",
    "$$x_{k+1} = F(x_{k})$$ schreiben mit $$F(x) := x - \\frac{f(x)}{f'(x)}.$$\n",
    "Damit lässt sich Satz\n",
    "[\\[s:newtonkonv\\]](#s:newtonkonv){reference-type=\"ref\"\n",
    "reference=\"s:newtonkonv\"} über die quadratische Konvergenz des\n",
    "Newton-Verfahrens auch mithilfe von Satz\n",
    "[\\[s:fpkonv\\]](#s:fpkonv){reference-type=\"ref\" reference=\"s:fpkonv\"}\n",
    "beweisen (Übung).\n",
    "\n",
    "Interpolation\n",
    "=============\n",
    "\n",
    "### Interpolation und Approximation\n",
    "\n",
    "Eine reelle Funktion $f(x)$ oder eine Datentabelle $(x_i, y_i)$,\n",
    "$i=0,1,\\ldots, n$ soll durch eine einfache Funktion $g(x)$ angenähert\n",
    "werden.\n",
    "\n",
    "-   **Approximation:**\n",
    "\n",
    "    -   $g$ wird so bestimmt, dass eine Funktionsnorm\n",
    "        $\\lVert g(x) - f(x) \\rVert$ bzw. Vektornorm\n",
    "        $\\lVert g(x_i) - y_i\\rVert$ minimal wird.\n",
    "\n",
    "    -   Typischerweise sind sehr viele Daten gegeben ($n$ ist sehr\n",
    "        groß), die mit statistischen bzw. Messfehlern behaftet sind.\n",
    "\n",
    "    -   Es soll eine möglichst glatte Kurve durch diese Datenwolke \n",
    "        gelegt werden. Beispiel: lineare Regression\\\n",
    "        ![image](figs/linear_regression.png){height=\"0.4\\\\textheight\"}\\\n",
    "        <https://commons.wikimedia.org/wiki/File:Linear_regression.svg>\n",
    "\n",
    "### Interpolation und Approximation\n",
    "\n",
    "-   **Interpolation:**\n",
    "\n",
    "    -   $g$ wird so konstruiert, dass sie an vorgegebenen Stellen mit\n",
    "        der gegebenen Funktion bzw. den Daten übereinstimmt:\n",
    "        $$g(x_i) = f(x_i) \\quad \\text{bzw.} \\quad g(x_i) = y_i, \\quad i=0,1,\\ldots, n.$$\n",
    "\n",
    "    -   Es sind nur wenige Daten gegeben ($n$ ist klein), und es ist\n",
    "        sinnvoll/wichtig, dass $g$ an den gegebenen Stellen $x_i$ exakt\n",
    "        mit den Funktionswerten $f(x_i)$ bzw. den Daten $y_i$\n",
    "        übereinstimmt.\\\n",
    "        ![image](figs/interpolation.png){height=\"0.4\\\\textheight\"}\\\n",
    "        <https://commons.wikimedia.org/wiki/File:Interpolation_example_polynomial.svg>\n",
    "\n",
    "### Interpolation und Approximation\n",
    "\n",
    "-   In diesem Kapitel beschäftigen wir uns nur mit der Interpolation.\n",
    "\n",
    "-   Als Interpolationsfunktionen $g$ kommen z.B. Polynome oder\n",
    "    trigonometrische Funktionen infrage.\n",
    "\n",
    "-   Wir betrachten hier nur die **Polynominterpolation**:\n",
    "\n",
    "    -   Interpolation von $f:[a,b]\\to\\mathbb{R}$ durch ein einziges\n",
    "        Polynom auf $[a,b]$\n",
    "\n",
    "    -   Stückweise Interpolation auf Teilintervallen (Polynomzug,\n",
    "        **Spline**)\n",
    "\n",
    "Polynominterpolation\n",
    "--------------------\n",
    "\n",
    "Gegeben seien $n+1$ reelle Wertepaare $(x_i, y_i)$, $i=0,1,\\ldots, n$,\\\n",
    "mit paarweise verschiedenen Stützstellen $x_i$.\\\n",
    "Dann gibt es genau ein Polynom $P_n(x)$ mit\n",
    "$\\mathsf{Grad}P_n \\leqslant n$, das die Interpolationsbedingung\n",
    "$$P_n(x_i) = y_i, \\quad i=0,1,\\ldots, n$$ erfüllt, nämlich\n",
    "$$P_n(x) = \\sum_{i=0}^n y_i L_i(x)$$ mit den\n",
    "**Lagrange-Polynomen**\n",
    "$$L_i(x) := \\prod_{\\substack{j=0\\\\j\\neq i}}^n \\frac{x-x_j}{x_i-x_j}.$$\n",
    "Es gilt $\\mathsf{Grad}L_i = n$ und $L_i(x_k) = \\delta_{ik}$.\n",
    "\n",
    "![image](figs/tafel.png){width=\"0.5cm\"}Beweis\n",
    "\n",
    "### Newton-Interpolation\n",
    "\n",
    "-   Die Berechnung der Lagrange-Polynome $L_i$ ist recht aufwendig.\n",
    "\n",
    "-   Wenn eine Stützstelle hinzukommt, müssen *alle* $L_i$ neu berechnet\n",
    "    werden!\n",
    "\n",
    "-   Geschickter wäre folgende Darstellung des Interpolationspolynoms:\n",
    "    $$\\begin{aligned}\n",
    "        P_n(x) = &&c_0 + c_1(x-x_0) + c_2(x-x_0)(x-x_1) + \\ldots \\\\\n",
    "        && + c_n(x-x_0)(x-x_1) \\cdots (x-x_{n-1}). \n",
    "      \\end{aligned}$$ mit noch zu bestimmenden Koeffizienten $c_i$.\n",
    "\n",
    "-   Kommt eine Stützstelle $x_{n+1}$ hinzu, muss für $P_{n+1}(x)$ nur\n",
    "    der letzte Koeffizient $c_{n+1}$ neu berechnet werden, alle anderen\n",
    "    bleiben gleich.\n",
    "\n",
    "### Horner-Schema\n",
    "\n",
    "Funktionswerte des Interpolationspolynoms können dann mit dem\n",
    "**Horner-Schema** berechnet werden: $$\\begin{aligned}\n",
    "    P_n(x) &=&c_0 + c_1(x-x_0) + c_2(x-x_0)(x-x_1) + \\ldots \\\\\n",
    "    &&+ c_n(x-x_0)(x-x_1) \\cdots (x-x_{n-1})\\\\\n",
    "    &=& c_0 + (x-x_0)\\{ c_1 + (x-x_1) [c_2 + (x-x_2)( \\\\\n",
    "    &&\\ldots c_{n-1} + (x-x_{n-1}) c_n)]\\}\n",
    "  \\end{aligned}$$\n",
    "\n",
    "$p := c_n$\\\n",
    "Für $k=n-1,n-2,\\ldots,0$:\\\n",
    "$p := c_k + (x-x_k) p$\\\n",
    "Für den so berechneten Wert gilt $p = P_n(x)$.\n",
    "\n",
    "![image](figs/notebook.png){width=\"0.5cm\"}Implementierung, Beispiel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9c3861",
   "metadata": {},
   "source": [
    "Wie können wir die Koeffizienten $c_k$ aus den Wertepaaren $(x_k, y_k)$\n",
    "berechnen?\n",
    "\n",
    "Es bezeichne $P^*_{k,k+1,\\ldots,k+j}(x)$ das Interpolationspolynom\n",
    "$j$-ten Grades zu den Wertepaaren $(x_{k+i}, y_{k+i})$,\n",
    "$i=0,1,\\ldots, j$.\\\n",
    "Dann gilt für $1\\leqslant j \\leqslant n$ die Rekursionsformel\n",
    "$$P^*_{k,\\ldots,k+j}(x) = \\frac{(x-x_k) P^*_{k+1,\\ldots,k+j}(x) - (x - x_{k+j}) P^*_{k,\\ldots,k+j-1}(x)}{x_{k+j} - x_k}.$$\n",
    "\n",
    "![image](figs/tafel.png){width=\"0.5cm\"}Beweis\n",
    "\n",
    "Wir definieren $[y_k] := y_k$ für $k=0,1,\\ldots, n$, und rekursiv\n",
    "$$[y_k, y_{k+1}, \\ldots, y_{k+j}] := \\frac{[y_{k+1}, \\ldots, y_{k+j}] - [y_{k}, \\ldots, y_{k+j-1}]}{x_{k+j} - x_k}$$\n",
    "für $j=2,3,\\ldots, n, \\; k=0,1, \\ldots, n-j$.\n",
    "\n",
    "Der führende Koeffizient von $P^*_{k,k+1,\\ldots,k+j}(x)$ ist\n",
    "$[y_k, y_{k+1}, \\ldots, y_{k+j}]$.\\\n",
    "Damit folgt insbesondere\n",
    "$$c_j = [y_0, y_1, \\ldots, y_j], \\quad j = 0,1,\\ldots,n.$$\n",
    "\n",
    "![image](figs/tafel.png){width=\"0.5cm\"}Beweis, Newton-Schema\n",
    "\n",
    "Für $k=0,1,\\ldots,n$:\\\n",
    "$c_k := y_k$\\\n",
    "Für $k=1,2,\\ldots,n$:\\\n",
    "Für $i=n,n-1,\\ldots,k$:\\\n",
    "$c_i := \\dfrac{c_i - c_{i-1}}{x_i - x_{i-k}}$\n",
    "\n",
    "![image](figs/notebook.png){width=\"0.5cm\"}Implementierung, Beispiel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81d4a39",
   "metadata": {},
   "source": [
    "[\\[satz:div_diff_aequi\\]]{#satz:div_diff_aequi\n",
    "label=\"satz:div_diff_aequi\"} Sind die Stützstellen\n",
    "**äquidistant**, d.h. $x_{k+1} - x_k = h$ für $k=0,1,\\ldots, n-1$,\n",
    "so gilt\n",
    "$$c_j = [y_0,y_1,\\ldots,y_j] = \\frac{1}{j! h^j} \\sum_{k=0}^j {j\\choose k} (-1)^{j+k} y_k.$$\n",
    "\n",
    "Beweis: Übung\n",
    "\n",
    "[\\[satz:polyinterpfehler\\]]{#satz:polyinterpfehler\n",
    "label=\"satz:polyinterpfehler\"} Gegeben seien eine Funktion\n",
    "$f \\in C^{n+1}[a,b]$ und die $n+1$ Stützstellen $x_i\\in[a,b]$,\n",
    "$i=0,1,\\ldots, n$. Sei $P_n$ das die Punkte $(x_i, f(x_i))$\n",
    "interpolierende Polynom vom Höchstgrad $n$ und\n",
    "$$\\omega(x) := (x-x_0)(x-x_1) \\cdots (x-x_n).$$ Dann gibt es zu jedem\n",
    "$\\tilde x\\in[a,b]$ ein $\\xi\\in(a,b)$ mit\n",
    "$$f(\\tilde x) - P_n(\\tilde x) = \\frac{\\omega(\\tilde x)f^{(n+1)}(\\xi)}{(n+1)!}.$$\n",
    "Damit gilt also\n",
    "$$|f(\\tilde x) - P_n(\\tilde x)| \\leqslant \\frac{|\\omega(\\tilde x)|}{(n+1)!}\n",
    "      \\max_{\\xi\\in[a,b]} |f^{(n+1)}(\\xi)|.$$\n",
    "\n",
    "![image](figs/tafel.png){width=\"0.5cm\"}Beweis\n",
    "![image](figs/notebook.png){width=\"0.5cm\"}Illustration, Beispiel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9a7324",
   "metadata": {},
   "source": [
    "### Hermite-Interpolation\n",
    "\n",
    "Zusätzlich zu den Stützwerten sollen an den Stützstellen jetzt noch\n",
    "Ableitungswerte vorgegeben werden:\\\n",
    "Gesucht ist ein Polynom $P_{2n+1}$ vom Höchstgrad $2n+1$mit\n",
    "$$P_{2n+1}(x_i) = y_i, \\quad P'_{2n+1}(x_i) = y_i', \\quad i = 0,1,\\ldots, n.$$\n",
    "Dazu werden alle Stützstellen doppelt gezählt:\n",
    "$x_0, x_0, x_1, x_1, \\ldots, x_n, x_n$. Das Interpolationspolynom hat\n",
    "jetzt die Form $$\\begin{aligned}\n",
    " P_{2n+1}(x) &=& c_0 + c_1(x-x_0) + c_2 (x-x_0)^2 + c_3(x - x_0)^2 (x-x_1) \\\\ &&+ x_4(x-x_0)^2(x-x_1)^2 + \\ldots \\\\ \n",
    "    &&+ c_{2n+1}(x-x_0)^2(x-x_1)^2 \\cdots (x-x_{n-1})^2(x-x_n) . \n",
    "  \\end{aligned}$$ Die Koeffizienten $c_k$ können wieder mit dem\n",
    "Newton-Schema bestimmt werden, wobei die dividierten Differenzen\n",
    "gleicher Stützstellen durch die Ableitung ersetzt werden:\n",
    "$$[y_k,y_k] = \\lim_{h\\to 0} \\frac{f(x_k+h) - f(x_k)}{(x_k + h) - x_k} = f'(x_k) = y_k'.$$\n",
    "![image](figs/tafel.png){width=\"0.5cm\"}Schema\n",
    "![image](figs/notebook.png){width=\"0.5cm\"}Beispiel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab845814",
   "metadata": {},
   "source": [
    "Spline-Interpolation\n",
    "--------------------\n",
    "\n",
    "### Stückweise Interpolation\n",
    "\n",
    "-   Interpolation von $f:[a,b]\\to\\mathbb{R}$ an den Stützstellen\n",
    "    $a = x_0 < x_1 < \\ldots < x_{n-1} < x_n = b$ durch ein einziges\n",
    "    Polynom führt oft zu großen Oszillationen besonders am Rand des\n",
    "    Intervalls.\n",
    "\n",
    "-   Alternative: Unterschiedliche Polynome niedrigen Grades in jedem\n",
    "    Teilintervall\n",
    "\n",
    "-   Einfachster Fall: Stückweise lineare Interpolation\\\n",
    "    ![image](figs/pw_lin_interp.png)\n",
    "    $$l(x) = f(x_k) + \\frac{f(x_{k+1}) - f(x_k)}{x_{k+1} - x_k}(x-x_k), \\; \n",
    "        x\\in [x_k , x_{k+1}], \\; k=0,\\ldots,n-1$$ $l(x)$ ist jedoch\n",
    "    nicht differenzierbar.\n",
    "\n",
    "<https://de.wikipedia.org/wiki/Datei:Linear_interpolation.svg>\n",
    "\n",
    "### Stückweise Interpolation\n",
    "\n",
    "0.6\n",
    "\n",
    "-   Besser: Stückweise kubische Interpolation $\\rightarrow$ kubische\n",
    "    **Splines**\n",
    "\n",
    "-   Engl. spline = Straklatte, elastische Latte aus Holz oder\n",
    "    Kunststoff, z.B. im Schiffbau verwendet\n",
    "\n",
    "-   Die Straklatte nimmt die Kurve $s(x)$ kleinster Krümmung an\n",
    "\n",
    "-   Die Krümmungsenergie ist durch die zweite Ableitung gegeben:\n",
    "    $$\\int_a^b s''(x)^2 \\, \\mathsf{d}x$$\n",
    "\n",
    "0.5 ![image](figs/spline_interp.png)\\\n",
    "![image](figs/straklatte.png){height=\"0.5\\\\textheight\"}\n",
    "\n",
    "<https://commons.wikimedia.org/wiki/File:Spline_interpolation.svg>\\\n",
    "<https://commons.wikimedia.org/wiki/File:Spline_(PSF).png>\n",
    "\n",
    "Es existiert genau eine Funktion $s:[a,b]\\to\\mathbb{R}$ mit den\n",
    "folgenden Eigenschaften:\n",
    "\n",
    "(i) $s(x_i) = y_i$, $i=0,1,\\ldots n$\n",
    "\n",
    "(ii) $s$ ist mindestens einmal stetig differenzierbar.\n",
    "\n",
    "(iii) Im Innern jedes Teilintervalls $(x_i, x_{i+1})$,\n",
    "      $i=0,1,\\ldots, n-1$,\\\n",
    "      ist $s$ mindestens viermal stetig differenzierbar.\n",
    "\n",
    "(iv) $s$ minimiert das Funktional\n",
    "     $$J[s] := {\\textstyle \\frac{1}{2}}\\int_a^b s''(x)^2 \\, \\mathsf{d}x.$$\n",
    "\n",
    "![image](figs/tafel.png){width=\"0.5cm\"}Beweis\n",
    "\n",
    "**Zusammenfassung** des Ergebnisses des konstruktiven Beweises:\\\n",
    "$s(x) = s_i(x)$ für $x\\in[x_i,x_{i+1}]$ für $i=0,1,\\ldots,n-1$, wobei\n",
    "$$s_i(x) = \\frac{1}{6} \\left( c_i \\frac{(x_{i+1} - x)^3}{h_i} \n",
    "    + c_{i+1} \\frac{(x - x_i)^3}{h_i} \\right) + b_i(x-x_i) + a_i$$ mit\n",
    "$h_i := x_{i+1} - x_i$.\\\n",
    "Zuerst löst man folgendes lineares Gleichungssystem für die $c_i$:\n",
    "$$\\frac{h_{i-1}}{6} c_{i-1} + \\frac{h_{i-1} + h_i}{3} c_i + \\frac{h_i}{6} c_{i+1}\n",
    "  = \\frac{y_{i+1} - y_i}{h_i} - \\frac{y_i - y_{i-1}}{h_{i-1}}$$ für\n",
    "$i=1,\\ldots,n-1$ sowie $c_0 = c_n = 0$.\\\n",
    "Dann setzt man $$a_i = y_i - \\frac{h_i^2}{6} c_i, \\qquad \n",
    "     b_i = \\frac{y_{i+1} - y_i}{h_i} - \\frac{h_i}{6} (c_{i+1} - c_i).$$\\\n",
    "![image](figs/notebook.png){width=\"0.5cm\"}Implementierung"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91034d14",
   "metadata": {},
   "source": [
    "**Bemerkungen**\n",
    "\n",
    "-   Das LGS hat die Form\n",
    "    $$\\gamma_i c_{i-1} + \\alpha_i c_i + \\beta_i c_{i+1} = \\delta_i.$$\n",
    "    Solch ein tridiagonales LGS lässt sich schnell mithilfe des\n",
    "    Thomas-Algorithmus lösen (Kapitel 3)!\n",
    "\n",
    "-   Anstelle der **natürlichen Randbedingungen**\n",
    "    $$s''(x_0) = s''(x_n) = 0 \\; \\Leftrightarrow \\; c_0 = c_n = 0$$ sind\n",
    "    auch möglich:\n",
    "\n",
    "    -   **Hermite-** (oder **vollständige**)\n",
    "        **Randbedingungen**\n",
    "        $$s'(x_0) = y_0', \\quad s'(x_n) = y_n',$$ wobei man $y_0', y_n'$\n",
    "        z.B. aus zu interpolierenden Funktion erhält\n",
    "\n",
    "    -   **periodische Randbedingungen**\n",
    "        $$s'(x_0) = s'(x_n), \\quad s''(x_0) = s''(x_n)$$\n",
    "\n",
    "Numerische Differentiation {#chap:numdiff}\n",
    "==========================\n",
    "\n",
    "**Ziel:** Näherungsweise Bestimmung der Ableitung(en) einer Funktion\n",
    "$f:[a,b]\\to\\mathbb{R}$\\\n",
    "**Idee:** Nähere $f$ durch Interpolationspolynom $P_n$ und leite $P_n$\n",
    "ab\\\n",
    "\n",
    "Gegeben seien $f\\in C^n[a,b]$ und Stützstellen\n",
    "$$a = x_0 < x_1 < \\ldots < x_{n-1} < x_n = n.$$ Es sei $y_i := f(x_i)$,\n",
    "$i=0,1,\\ldots, n$. Dann existiert ein $\\xi\\in[a,b]$, so dass\n",
    "$$f^{(n)}(\\xi) = n! \\, [y_0, y_1, \\ldots, y_n].$$\n",
    "\n",
    "![image](figs/tafel.png){width=\"0.5cm\"}Beweis\\\n",
    "Die genäherten Ableitungen können also über das Newton-Schema erzeugt\n",
    "werden. Für äquidistante Stützstellen gilt die explizite Formel aus Satz\n",
    "[\\[satz:div_diff_aequi\\]](#satz:div_diff_aequi){reference-type=\"ref\"\n",
    "reference=\"satz:div_diff_aequi\"}.\n",
    "\n",
    "Üblicherweise wird mit diesen Ausdrücken $f^{(n)}(x_0)$ approximiert.\\\n",
    "Man spricht dann auch von **Vorwärts-Differenzenquotienten/\\\n",
    "finiten Differenzen**.\\\n",
    "Bei äquistanten Stützstellen mit Schrittweite $h$ erhält man\n",
    "$$\\begin{aligned}\n",
    "    f'(x_0) &\\approx& \\frac{y_1 - y_0}{h} \\\\\n",
    "    f''(x_0) &\\approx& \\frac{y_2 - 2y_1 + y_0}{h^2} \\\\\n",
    "    f'''(x_0) &\\approx& \\frac{y_3 - 3y_2 + 3 y_1 - y_0}{h^3} \\\\\n",
    "    &\\vdots\n",
    "  \\end{aligned}$$ Vgl. die Lösung zu Aufgabe 7.2.\n",
    "\n",
    "Sei $f\\in C^{n+1}([a,b])$ und seien $a=x_0, x_1, \\ldots, x_n=b$\n",
    "äquidistante Stützstellen mit Schrittweite $h$. Setze $y_i := f(x_i)$,\n",
    "$i=0,1,\\ldots, n$.\\\n",
    "Dann gilt\n",
    "$$f^{(n)}(x_0) = n! \\, [y_0, y_1, \\ldots, y_n] + \\mathcal{O}(h).$$\n",
    "\n",
    "![image](figs/tafel.png){width=\"0.5cm\"}Beweis\n",
    "\n",
    "Approximationen höherer Fehlerordnung erhält man durch\n",
    "Interpolationspolynome höherer Ordnung, z.B. interpoliere $f$ an drei\n",
    "äquidistanten Stützstellen $y_0,y_1,y_2$ und setze\n",
    "$f'(x_1) \\approx P_3'(x_1)$.\n",
    "\n",
    "Sei $f:[a,b]\\to\\mathbb{R}$ und seien $x_i\\in[a,b]$ äquidistante\n",
    "Stützstellen mit Schrittweite $h$, $y_i := f(x_i)$. Dann gilt:\n",
    "$$\\begin{aligned}\n",
    "      f\\in C^3([a,b]) &\\Rightarrow& f'(x_i) = \\frac{y_{i+1} - y_{i-1}}{2h} + \\mathcal{O}(h^{{2}}),\\medskip\\\\\n",
    "      f\\in C^4([a,b]) &\\Rightarrow& f''(x_i) = \\frac{y_{i+1} - 2y_i + y_{i-1}}{h^2} + \\mathcal{O}(h^{{2}}).\n",
    "    \\end{aligned}$$\n",
    "\n",
    "![image](figs/tafel.png){width=\"0.5cm\"}Beweis\\\n",
    "Finite Differenzen für höhere Ableitungen erhält man daraus rekursiv:\n",
    "$f^{(n)}(x_i) = y_i^{(n)} + \\mathcal{O}(h^2)$ mit\n",
    "$y_i^{(0)} := y_i = f(x_i)$ und $$y_i^{(n)} = \\begin{cases} \n",
    "    \\frac{y_{i+1}^{(n-1)} - y_{i-1}^{(n-1)}}{2h} & \\text{falls } n \\text{ ungerade}\\smallskip\\\\\n",
    "    \\frac{y_{i+1}^{(n-2)} - 2 y_i^{(n-2)} + y_{i-1}^{(n-2)}}{h^2} & \\text{falls } n \\text{ gerade}\n",
    "  \\end{cases}$$\n",
    "\n",
    "### Rundungsfehler\n",
    "\n",
    "Wegen der Division der Differenzen im Zähler durch Potenzen von $h$\n",
    "(klein!) sind Rundungsfehler bei finiten Differenzen besonders\n",
    "gefährlich. Wird $h$ sehr klein, so wird der **Rundungsfehler**\n",
    "größer als der **Diskretisierungsfehler**.\\\n",
    "![image](figs/notebook.png){width=\"0.5cm\"}Beispiel\\"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077030f0",
   "metadata": {},
   "source": [
    "Nach Satz\n",
    "[\\[satz:Rundungsfehler\\]](#satz:Rundungsfehler){reference-type=\"ref\"\n",
    "reference=\"satz:Rundungsfehler\"} ist der relative Fehler bei der Rundung\n",
    "von der Größenordnung der Maschinengenauigkeit $\\mathsf{eps}$, und somit\n",
    "$$\\begin{aligned}\n",
    "    \\frac{\\mathsf{rd}(f(x+h) - f(x))}{h} &=& \\frac{f(x+h) - f(x)}{h} + \\mathcal{O}\\left(\\frac{\\mathsf{eps}\\, f(x)}{h}\\right) \\\\\n",
    "    &=& f'(x) + \\mathcal{O}(h \\, f''(x)) + \\mathcal{O}\\left(\\frac{\\mathsf{eps}\\, f(x)}{h}\\right)\n",
    "  \\end{aligned}$$ Der Rundungsfehler ist kleiner als der\n",
    "Diskretisierungsfehler, falls\n",
    "$$h \\, f''(x) \\gtrsim \\frac{\\mathsf{eps}\\, f(x)}{h} \\Leftrightarrow {h \\gtrsim \\sqrt{\\mathsf{eps}\\, \\frac{f(x)}{f''(x)}}}.$$\n",
    "\n",
    "Numerische Integration\n",
    "======================\n",
    "\n",
    "Newton-Cotes-Formeln\n",
    "--------------------\n",
    "\n",
    "### Newton-Cotes-Formeln\n",
    "\n",
    "-   **Ziel:** Näherungsweise Bestimmung von\n",
    "    $I := \\int_a^b f(x) \\mathsf{d}x$\n",
    "\n",
    "-   **Idee:** Ersetze $f$ durch Interpolationspolynom $P_m$ an $m+1$\n",
    "    Stützstellen und integriere dieses exakt:\n",
    "    $I \\approx \\tilde I_m := \\int_a^b P_m(x) \\mathsf{d}x$\n",
    "\n",
    "-   Lagrange-Darstellung: $P_m(x) = \\sum_{i=0}^m f(x_i) L_i(x)$\n",
    "    $$\\Rightarrow \\tilde I_m = (b-a) \\sum_{i=0}^m w_i f(x_i), \\quad\n",
    "        w_i = \\frac{1}{b-a} \\int_a^b L_i(x) \\mathsf{d}x$$\n",
    "\n",
    "-   Für äquidistante Stützstellen $x_i = a + ih$ mit $h=(b-a)/m$ :\n",
    "    $$w_i = \\frac{1}{b-a} \\int_a^b \\prod_{\\substack{j=0\\\\j\\neq i}} \\frac{x-x_j}{x_i-x_j}\\mathsf{d}x = \\frac{1}{m} \\int_0^m \\prod_{\\substack{j=0\\\\j\\neq i}} \\frac{s-j}{i-j} \\mathsf{d}s$$\n",
    "    (Substitution $s=(x-a)/h$)\n",
    "\n",
    "![image](figs/tafel.png){width=\"0.5cm\"}Beispiel: Trapezregel,\n",
    "Simpson-Regel\n",
    "\n",
    "### Newton-Cotes-Formeln\n",
    "\n",
    "0.77 Die Simpson-Regel wird auch Kepler'sche Fassregel genannt (nach\n",
    "Johannes Kepler, 1571-1630)\\\n",
    "<http://www.keplerraum.at/fass.html>\n",
    "\n",
    "0.23 ![image](figs/kepler_fass.jpg){width=\"\\\\textwidth\"}\n",
    "\n",
    "Eine Quadraturformel besitzt den **Genauigkeitsgrad**\n",
    "$m\\in\\mathbb{N}$, wenn sie alle Polynome vom Höchstgrad $m$ exakt\n",
    "integriert und $m$ die größte Zahl mit dieser Eigenschaft ist.\n",
    "\n",
    "Ist $f$ ein Polynom vom Höchstgrad $m$, so ist das Interpolationspolynom\n",
    "$P_m$ mit $f$ identisch, und die zugehörige Quadraturformel ist exakt:\n",
    "\n",
    "Zu $m+1$ paarweise verschiedenen Stützstellen gibt es genau eine\n",
    "Newton-Cotes-Formel, deren Genauigkeitsgrad mindestens $m$ ist.\n",
    "\n",
    "### Quadraturfehler\n",
    "\n",
    "Nach Satz\n",
    "[\\[satz:polyinterpfehler\\]](#satz:polyinterpfehler){reference-type=\"ref\"\n",
    "reference=\"satz:polyinterpfehler\"} gilt für den Fehler der\n",
    "Polynominterpolation:\n",
    "$$f(x) - P_m(x) = \\frac{\\omega(x)f^{(m+1)}(\\xi)}{(m+1)!}  \\quad\n",
    "  \\text{mit} \\quad \\omega(x) = \\prod_{i=0}^m (x-x_i), \\quad \\xi\\in(a,b).$$\n",
    "Damit folgt für den Quadraturfehler $E_m[f]:= \\tilde I_m - I$ der\n",
    "Newton-Cotes-Formel $m$-ten Grades:\n",
    "$$E_m[f] = \\frac{1}{(m+1)!} \\int_a^b f^{(m+1)}(\\xi(x)) \\omega(x) \\mathsf{d}x.$$\n",
    "![image](figs/tafel.png){width=\"0.5cm\"}Beispiel: Trapezregel\n",
    "\n",
    "### Übersicht: (Globale) Newton-Cotes-Formeln\n",
    "\n",
    "$\\,$\\\n",
    "\n",
    "  $m$   $(w_k)_{k=0,1,\\ldots m}$          $|E_m[f]| \\leqslant$                                                                               Name\n",
    "  ----- --------------------------------- -------------------------------------------------------------------------------------------------- -----------------------------\n",
    "                                                                                                                                             \n",
    "  $1$   ${\\textstyle \\frac{1}{2}}(1,1)$   $\\tfrac{1}{12} (b-a)^3 \\max_{\\xi\\in**a,b]} |f''(\\xi)|$                                              [Trapezregel**\n",
    "  $2$   $\\tfrac{1}{6} (1,4,1)$            $\\tfrac{1}{90} \\left(\\frac{b-a}{2}\\right)^{{5}} \\max_{\\xi\\in**a,b]} |f^{{(4)}}(\\xi)|$   [Simpson-Regel**\n",
    "  $3$   $\\tfrac{1}{8} (1,3,3,1)$          $\\tfrac{3}{80} \\left(\\frac{b-a}{4}\\right)^5 \\max_{\\xi\\in[a,b]} |f^{(4)}(\\xi)|$                     Newton-$\\tfrac{3}{8}$-Regel\n",
    "  $4$   $\\tfrac{1}{90} (7,32,12,32,7)$    $\\tfrac{8}{945} \\left(\\frac{b-a}{5}\\right)^7 \\max_{\\xi\\in[a,b]} |f^{(6)}(\\xi)|$                    Milne-Regel\n",
    "\n",
    "\\\n",
    "Ab $m=8$ treten negative Gewichte $w_i$ auf und die Newton-Cotes-\n",
    "Formeln werden numerisch instabil.\\\n",
    "Der Vollständigkeit halber noch die **Mittelpunktsregel** (eine\n",
    "**offene** Newton-Cotes-Formel, da $a,b$ keine Stützstellen sind):\n",
    "$$\\int_a^b f(x) \\mathsf{d}x \\approx (b-a) \\, f\\left(\\frac{a+b}{2}\\right), \\qquad |E[f]| \\leqslant  \\frac{1}{24} (b-a)^3 \\max_{\\xi\\in[a,b]}|f''(\\xi)|$$\n",
    "\n",
    "Summierte Newton-Cotes-Formeln\n",
    "------------------------------\n",
    "\n",
    "### Summierte Newton-Cotes-Formeln\n",
    "\n",
    "Zur Erhöhung der Genauigkeit wird das Intervall $[a,b]$ in $n$ gleiche\n",
    "Teile zerlegt:\n",
    "$$x_j = a + j h, \\quad j=0,1,\\ldots,n, \\quad h = \\frac{b-a}{n}.$$ Die\n",
    "Newton-Cotes-Formeln werden an diesen Stützstellen mehrfach\n",
    "aneinandergesetzt. So erhält man\n",
    "\n",
    "-   die summierte Trapezregel\n",
    "    $$I\\approx T(h) := \\frac{h}{2} [f(x_0) + 2f(x_1) + \\ldots + 2f(x_{n-1}) + f(x_n)]$$\n",
    "\n",
    "-   für gerades $n$ die summierte Simpson-Regel\n",
    "    $$I\\approx S(h) := \\frac{h}{3} [f(x_0) + 4f(x_1) + 2 f(x_2) + \\ldots + 2f(x_{n-2}) + 4 f(x_{n-1})+ f(x_n)]$$\n",
    "\n",
    "![image](figs/tafel.png){width=\"0.5cm\"}Herleitung, Skizze\n",
    "\n",
    "$f:[a,b]\\to\\mathbb{R}$ sei zweimal bzw. viermal stetig differenzierbar.\\\n",
    "Dann gilt für eine äquidistante Zerlegung von $[a,b]$ mit Schrittweite\n",
    "$h$: $$\\begin{aligned}\n",
    "    |T(h) - I| &\\leqslant& \\frac{b-a}{12} {h^2} \\max_{\\xi\\in[a,b]} |f''(\\xi)|,\\\\\n",
    "    |S(h) - I| &\\leqslant& \\frac{b-a}{180} {h^4} \\max_{\\xi\\in[a,b]} |f^{(4)}(\\xi)|.\n",
    "  \\end{aligned}$$\n",
    "\n",
    "![image](figs/tafel.png){width=\"0.5cm\"}Beweis\\\n",
    "![image](figs/notebook.png){width=\"0.5cm\"}Implementierung"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d13ebb",
   "metadata": {},
   "source": [
    "Romberg-Verfahren\n",
    "-----------------\n",
    "\n",
    "### Romberg-Verfahren\n",
    "\n",
    "**Idee:** Berechne die summierte Trapezregel $T(h)$ für eine Folge\n",
    "kleiner werdender Schrittweiten $h$ und extrapoliere nach $h=0$.\n",
    "\n",
    "Der Fehler der Trapezregel lässt sich wie folgt entwickeln:\n",
    "$$T(h) - I = c_1 h^2 + c_2 h^4 + \\ldots + c_N h^{2N} + \\mathcal{O}(h^{2N+2}).$$\n",
    "(Explizit gilt für $f\\in C^\\infty([a,b])$ die\n",
    "Euler-MacLaurin-Summenformel\n",
    "$$T(h) - I = \\sum_{k=1}^\\infty \\frac{B_{2k}}{(2k)!} h^{2k}\n",
    "      \\left[ f^{(2k-1)}(b) - f^{(2k-1)}(a) \\right],$$ wobei $B_k$ die\n",
    "Bernoulli-Zahlen sind.)\n",
    "\n",
    "Für die Folge von Schrittweiten $h_k := (b-a)/2^k$, $k=0, 1,\n",
    "    \\ldots, m$, setze man $T_{k,0} := T(h_k)$ und berechne rekursiv\n",
    "(Aitken-Neville-Schema)\n",
    "$$T_{k,j} = \\frac{4^j T_{k,j-1} - T_{k-1,j-1}}{4^j - 1}, \\quad\n",
    "    k=1, 2, \\ldots, m, \\quad j = 1, 2, \\ldots, k.$$ Dann ist $T_{m,m}$\n",
    "in der Regel die genaueste Approximation des Integrals. Für\n",
    "$f\\in C^\\infty([a,b])$ gilt $\\lim_{m\\to\\infty} T_{m,m} =\n",
    "    \\int_a^b f(x) \\mathsf{d}x$.\n",
    "\n",
    "![image](figs/tafel.png){width=\"0.5cm\"}Schema, Herleitung\\\n",
    "![image](figs/notebook.png){width=\"0.5cm\"}Implementierung"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec16f09",
   "metadata": {},
   "source": [
    "**Bemerkungen:**\n",
    "\n",
    "-   In der ersten Spalte der Dreiecksmatrix $T_{k,j}$ stehen die Werte\n",
    "    der Trapezregel zu den Schrittweiten $h_k$, in der zweiten die\n",
    "    Simpson-Regel, die dritte heißt Boole-Regel, usw.\n",
    "\n",
    "-   Bei der Berechnung der Trapezregeln kann man Funktionswerte\n",
    "    \"recyclen\": Für $k=2,3,\\ldots$ gilt\n",
    "    $$T_{k,0} = {\\textstyle \\frac{1}{2}}T_{k-1,0} + h_k [f(a+h_k) + f (a + 3 h_k) +\n",
    "          \\ldots + f(b - 3 h_k) + f (b - h_k)] \\vspace{-0.3cm}$$\n",
    "    ![image](figs/tafel.png){width=\"0.5cm\"}Skizze\n",
    "\n",
    "### Ausblick: Adaptive Integration\n",
    "\n",
    "Moderne Algorithmen verwenden adaptive Verfahren. Die Grundidee:\n",
    "\n",
    "Das Integrationsintervall wird zunächst in $n$ gleiche Teile geteilt.\n",
    "Auf jedem Teilintervall wird das Integral auf zwei Arten approximiert,\n",
    "z.B.\n",
    "\n",
    "-   $I_1$: Trapezregel\n",
    "\n",
    "-   $I_2$: Simpson-Regel\n",
    "\n",
    "Dann ist $|I_1 - I_2|$ ein Maß für den numerischen Fehler in diesem\n",
    "Teilintervall. Das Teilintervall wird nun solange halbiert, bis\n",
    "$|I_1 - I_2|$ kleiner als eine vorgegebene Toleranz ist.\n",
    "\n",
    "Lineare Gleichungssysteme: Iterative Verfahren\n",
    "==============================================\n",
    "\n",
    "### Motivation\n",
    "\n",
    "-   Typische Anwendung: Diskretisierung partieller\n",
    "    Differentialgleichungen mit Differenzenmethoden (Kapitel\n",
    "    [6](#chap:numdiff){reference-type=\"ref\" reference=\"chap:numdiff\"})\\\n",
    "    ![image](figs/tafel.png){width=\"0.5cm\"}Beispiel\n",
    "\n",
    "-   Man erhält ein lineares Geichungssystem\n",
    "    $$\\sum_{j=1}^n a_{ij} x_j = b_i, \\quad i = 1,2,\\ldots n$$ mit einer\n",
    "    **großen dünnbesetzten Matrix** $A = (a_{ij})$\n",
    "\n",
    "-   Diese haben in $d>1$ Dimensionen keine zusammenhängende Bandstruktur\n",
    "    mehr, und es existiert kein schnelles direktes Verfahren wie der\n",
    "    Thomas-Algorithmus für Bandmatrizen (Algorithmus\n",
    "    [\\[algo:thomas\\]](#algo:thomas){reference-type=\"ref\"\n",
    "    reference=\"algo:thomas\"})\n",
    "\n",
    "-   Stattdessen kann man **iterative Verfahren** verwenden, die\n",
    "    eine Folge von immer besseren Approximationen der Lösung erzeugen\n",
    "\n",
    "-   Jeder Iterationsschritt nutzt die Dünnbesetztheit der Matrix optimal\n",
    "    aus\n",
    "\n",
    "Relaxationsverfahren\n",
    "--------------------\n",
    "\n",
    "Wir nehmen an, dass $a_{ii}\\neq 0$, $i=1,2,\\ldots, n$ und lösen die\n",
    "$i$-te Gleichung nach $x_i$:\n",
    "\n",
    "$$x_i^{(k+1)} = -\\frac{1}{a_{ii}} \\left( \\sum_{\\substack{j=1\\\\j\\neq i}}^n a_{ij} x_j^{(k)} - b_i \\right), \\quad i=1,2,\\ldots, n, \\quad k=0, 1, \\ldots$$\n",
    "\n",
    "Schreibt man $A = D - L - U$ mit einer Diagonalmatrix $D$, strikten\n",
    "unteren Dreiecksmatrix $L$ und strikten oberen Dreiecksmatrix $U$,\\\n",
    "so lautet die Iterationsvorschrift\n",
    "$$x^{(k+1)} = D^{-1} (L + U) x^{(k)} + D^{-1} b = T_\\mathsf{J} x^{(k)} + c_\\mathsf{J}$$\n",
    "mit der **Iterationsmatrix** $T_\\mathsf{J} := D^{-1} (L+U)$ und\n",
    "$c_\\mathsf{J} := D^{-1} b$.\n",
    "\n",
    "Alternativ kann man diejenigen neuen Komponenten $x_j^{(k+1)}$, die\n",
    "bereits berechnet wurden, sofort nutzen:\n",
    "\n",
    "$$\\begin{aligned}\n",
    " x_i^{(k+1)} = -\\frac{1}{a_{ii}} \\left( \\sum_{j=1}^{i-1} a_{ij} x_j^{(k+1)} + \\sum_{j=i+1}^n a_{ij} x_j^{(k)} - b_i \\right), \\\\\n",
    "        i=1,2,\\ldots, n, \\quad k=0, 1, \\ldots \\end{aligned}$$\n",
    "\n",
    "![image](figs/tafel.png){width=\"0.5cm\"}Erläuterung\\\n",
    "**Bemerkung:** Der Algorithmus hängt entscheidend von der Sortierung der\n",
    "Unbekannten ab.\\\n",
    "Diesmal lautet die Iterationsvorschrift also $$\\begin{aligned}\n",
    " &&x^{(k+1)} = D^{-1} (L x^{(k+1)} + U x^{(k)} + b) \\\\\n",
    "           &\\Leftrightarrow& x^{(k+1)} = (D - L)^{-1} U x^{(k)} + (D - L)^{-1} b\n",
    "           = T_\\mathsf{GS} x^{(k)} + c_\\mathsf{GS}\n",
    "        \\end{aligned}$$ mit $T_\\mathsf{GS} := (D - L)^{-1} U$ und\n",
    "$c_\\mathsf{GS} := (D - L)^{-1} b$.\n",
    "\n",
    "Für beide Verfahren kann man einen **Relaxationsparameter**\n",
    "$\\omega$ einführen. Ist $\\Delta x^{(k+1)} := x^{(k+1)} - x^{(k)}$ in der\n",
    "ursprünglichen Iterationsvorschrift, so lautet die modifizierte\n",
    "Iterationsvorschrift\n",
    "$$x^{(k+1)} = x^{(k)} + \\omega \\, \\Delta x^{(k+1)}.$$ (Für $\\omega = 1$\n",
    "erhält man offensichtlich das ursprüngliche Verfahren.)\\\n",
    "Das Jacobi-Verfahren wird damit zu\n",
    "\n",
    "$$\\begin{aligned}\n",
    "        x_i^{(k+1)} = (1 -\\omega) x_i^{(k)} -\\frac{\\omega}{a_{ii}} \\left( \\sum_{\\substack{j=1\\\\j\\neq i}}^n a_{ij} x_j^{(k)} - b_i \\right), \\\\\n",
    "        i=1,2,\\ldots, n, \\quad k=0, 1, \\ldots \n",
    "        \\end{aligned}$$\n",
    "\n",
    "mit der Relaxationsmatrix\n",
    "$T_\\mathsf{JOR}(\\omega) = (1-\\omega) \\mathbb{I} + \\omega D^{-1} (L+U)$\\\n",
    "und $c_\\mathsf{JOR}(\\omega) = \\omega D^{-1} b$.\n",
    "\n",
    "Analog erhält man für das Gauss-Seidel-Verfahren\n",
    "\n",
    "$$\\begin{aligned}\n",
    "        x_i^{(k+1)} = (1 -\\omega) x_i^{(k)} -\\frac{\\omega}{a_{ii}} \\left( \\sum_{j=1}^{i-1} a_{ij} x_j^{(k+1)} + \\sum_{j=i+1}^n a_{ij} x_j^{(k)} - b_i \\right), \\\\\n",
    "        i=1,2,\\ldots, n, \\quad k=0, 1, \\ldots \n",
    "        \\end{aligned}$$\n",
    "\n",
    "mit der Relaxationsmatrix\n",
    "$T_\\mathsf{SOR}(\\omega) = (D-\\omega L)^{-1} [(1-\\omega)D + \\omega U]$\\\n",
    "und $c_\\mathsf{JOR} = \\omega (D-\\omega L)^{-1} b$.\\\n",
    "![image](figs/notebook.png){width=\"0.5cm\"}Implementierung der Verfahren,\n",
    "Beispiel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febed896",
   "metadata": {},
   "source": [
    "Konvergenzbetrachtungen\n",
    "-----------------------\n",
    "\n",
    "Wir haben das LGS also auf verschiedene Arten als Fixpunktgleichung\n",
    "geschrieben: $$Ax= b \\; \\Leftrightarrow \\; x = Tx + c.$$ Die\n",
    "Relaxationsverfahren sind die zugehörigen Fixpunktiterationen.\n",
    "\n",
    "Die Fixpunktiteration $$x^{(k+1)} = T x^{(k)} + c, \\quad k=0,1,\\ldots$$\n",
    "konvergiert genau dann für beliebigen Startvektor $x^{(0)}$ gegen die\n",
    "Lösung $x$, falls der Spektralradius $\\sigma(T) < 1$.\n",
    "\n",
    "Hierbei ist der **Spektralradius**\n",
    "$\\sigma(T) = \\max_i |\\lambda_i|$ der betragsmäßig größte der (i.A.\n",
    "komplexen) Eigenwerte $\\lambda_i$ von $T$.\\\n",
    "![image](figs/tafel.png){width=\"0.5cm\"}Beweis\n",
    "\n",
    "Wie beim Banach'schen Fixpunktsatz (Satz\n",
    "[\\[satz:banach\\]](#satz:banach){reference-type=\"ref\"\n",
    "reference=\"satz:banach\"}) gilt eine Abschätzung für die Fehler\n",
    "$e^{(k)} := x^{(k)} - x$:\n",
    "$$\\lVert {e^{(k+1)}} \\rVert_2 \\leqslant \\sigma(T) \\, \\lVert {e^{(k)}} \\rVert_2.$$\n",
    "$\\sigma(T)$ bestimmt also die **Konvergenzgeschwindigkeit**.\\\n",
    "Für manche LGS, z.B. Diskretisierungen einfacher partieller\n",
    "Differentialgleichungen, kann man den Spektralradius der\n",
    "Iterationsmatrizen explizit berechnen.\n",
    "\n",
    "Die folgenden Sätze machen Aussagen für allgemeine Matrizen $A$.\\\n",
    "Wir benötigen folgende Voraussetzung:\n",
    "\n",
    "Eine Matrix $A\\in\\mathbb{R}^{n\\times n}$ heißt **irreduzibel**\n",
    "oder **unzerlegbar**, falls für je zwei beliebige nichtleere und\n",
    "disjunkte Teilmengen $I$ und $J$ von $M := \\{1,2,\\ldots, n\\}$ mit\n",
    "$I\\cup J = M$ stets Indizes $i\\in I$ und $j\\in J$ existieren, so dass\n",
    "$a_{ij}\\neq 0$.\\\n",
    "Äquivalentes Kriterium:\\\n",
    "$A$ werde ein gerichteter Graph mit $n$ Knoten zugeordnet, der genau\n",
    "dann eine gerichtete Kante vom Knoten $i$ zum Knoten $j$ besitzt, falls\n",
    "$a_{ij} \\neq 0$. Dann ist $A$ genau dann irreduzibel, falls es für alle\n",
    "$i,j\\in M$ einen gerichteten Weg vom Knoten $i$ zum Knoten $j$ gibt.\n",
    "\n",
    "![image](figs/tafel.png){width=\"0.5cm\"}Beispiel\n",
    "\n",
    "Eine irreduzible und schwach diagonaldominante Matrix (Def.\n",
    "[\\[defi:diagonaldominant\\]](#defi:diagonaldominant){reference-type=\"ref\"\n",
    "reference=\"defi:diagonaldominant\"}) ist invertierbar und hat\n",
    "nichtverschwindende Diagonalelemente.\n",
    "\n",
    "a)  Für eine irreduzible, schwach diagonaldominante Matrix $A$\n",
    "    konvergiert das Jacobi-Verfahren.\n",
    "\n",
    "b)  Konvergiert das Jacobi-Verfahren, dann konvergiert auch das\n",
    "    JOR-Verfahren für $0<\\omega\\leqslant 1$.\n",
    "\n",
    "c)  Konvergiert das Jacobi-Verfahren *und* ist $A$ außerdem symmetrisch\n",
    "    und positiv definit, dann konvergiert das JOR-Verfahren sogar für\n",
    "    alle $\\omega$ mit\n",
    "    $$0<\\omega < \\frac{2}{1-\\lambda_\\mathsf{min}}\\leqslant 2,$$ wobei\n",
    "    $\\lambda_\\mathsf{min}$ der kleinste (negative) Eigenwert von\n",
    "    $T_\\mathsf{J}$ ist.\n",
    "\n",
    "![image](figs/tafel.png){width=\"0.5cm\"}Beispiel einer symmetrischen und\n",
    "positiv definiten Matrix, für die das Jacobi-Verfahren *nicht*\n",
    "konvergiert\n",
    "\n",
    "a)  Ist $A$ entweder strikt diagonaldominant, oder irreduzibel und\n",
    "    schwach diagonaldominant, dann konvergiert das SOR-Verfahren für\n",
    "    $0<\\omega\\leqslant 1$ (und damit auch das Gauss-Seidel-Verfahren,\n",
    "    $\\omega=1$).\n",
    "\n",
    "b)  Das SOR-Verfahren konvergiert höchstens für $0<\\omega<2$.\n",
    "\n",
    "c)  Ist $A$ symmetrisch und positiv definit, dann konvergiert das\n",
    "    SOR-Verfahren tatsächlich für alle $\\omega$ mit $0<\\omega<2$.\n",
    "\n",
    "![image](figs/tafel.png){width=\"0.5cm\"}![image](figs/notebook.png){width=\"0.5cm\"}Beispiel:\n",
    "Zweidimensionale Poisson-Gleichung,\\"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e82f53",
   "metadata": {},
   "source": [
    "Diskretisierung mit finiten Differenzen\\\n",
    "Hier lässt sich der Spektralradius für das Jacobi-Verfahren explizit\n",
    "berechnen:\n",
    "$$\\sigma(T_\\mathsf{J}) = \\cos(\\pi h) = \\mathcal{O}(1 - h^2).$$ Für\n",
    "kleine $h$ konvergiert das Verfahren also sehr langsam.\\\n",
    "Das SOR-Verfahren konvergiert etwas schneller mit Rate\n",
    "$\\mathcal{O}(1 - h)$\\\n",
    "für optimal gewähltes $\\omega$.\n",
    "\n",
    "### Ausblick: Mehrgitterverfahren\n",
    "\n",
    "-   Beobachtung (s.o.): Auf gröberen Gittern konvergieren die\n",
    "    Relaxationsverfahren für die Finite-Differenzen-Matrix schneller.\n",
    "\n",
    "-   Idee: Führe ein paar Iterationen auf dem feinen Gitter aus, berechne\n",
    "    das Residuum $r = Ax - b$ und interpoliere dies auf ein gröberes\n",
    "    Gitter.\n",
    "\n",
    "-   Iteriere die Gleichung für den Fehler $A e = -r$ (Nachiteration) auf\n",
    "    dem gröberen Gitter.\n",
    "\n",
    "-   Interpoliere die so erhaltene Korrektur $e$ zurück auf das feinere\n",
    "    Gitter und korrigiere die Lösung dort.\n",
    "\n",
    "-   Der Prozess lässt sich rekursiv auf einer Hierarchie immer gröberer\n",
    "    Gitter fortsetzen.\n",
    "\n",
    "-   Die so erhaltenen Mehrgitterverfahren (Multigrid)\\\n",
    "    (Fedorenko, Bachwalow, Brandt, Hackbusch, $\\ldots \\sim$ 1970)\\\n",
    "    gehören zu den schnellsten bekannten Lösungsverfahren für große\n",
    "    dünnbesetzte LGS.\n",
    "\n",
    "Multigrid V-Cycle\\\n",
    "![image](figs/multigrid.png){width=\"\\\\textwidth\"}\\\n",
    "Quelle: H. Ibeid, L. Olson, W. Gropp: FFT, FMM, and multigrid on the\n",
    "road to exascale: Performance challenges and opportunities, *J. Parallel\n",
    "& Distrib. Comp.* **136**, 63--74 (2020)\n",
    "\n",
    "[^1]: Heinz Rutishauser\n",
    "\n",
    "[^2]: nach dem persischen Rechenmeister und Astronomen al-Chwarizmi, um\n",
    "    825\n",
    "\n",
    "[^3]: wenn man Darstellungen ausschließt, die auf $\\overline{b-1}$\n",
    "    enden: $(0.\\overline{9})_{10} = (1)_{10}$\n",
    "\n",
    "[^4]: In der IEEE 754-Norm (s.u.) ist $E=0$ für Sonderfälle vorbehalten,\n",
    "    so dass $\\mathsf{realmin}= 2^{-2^{r-1} + 2}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c62118a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
