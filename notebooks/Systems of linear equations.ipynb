{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Systems of linear equations\n",
    "The solution of a system of linear equations $Ax=b$ is obtained as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "A = np.array([[1, 2], [3, -1]])\n",
    "b = np.array([-1, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1. -1.]\n"
     ]
    }
   ],
   "source": [
    "x = np.linalg.solve(A,b)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check that this really is a solution, you should always compute the residual, which should vanish (to machine precision):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.4408921e-16 0.0000000e+00]\n"
     ]
    }
   ],
   "source": [
    "r = A.dot(x)-b\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same solution is obtained using the command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1. -1.]\n"
     ]
    }
   ],
   "source": [
    "x = np.linalg.inv(A).dot(b)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The difference is that this requires computing the inverse of $A$, which is time consuming, whereas `solve(A,b)` applies a fast algorithm for solving linear equations, which does not require the inverse explicitly. This becomes relevant for large systems:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.834245866\n",
      "2.5875389249999996\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "print(timeit.timeit(stmt='np.linalg.solve(A,b)',setup='import numpy as np; A = np.random.rand(1000,1000); b = np.random.rand(1000,1)',number=100))\n",
    "print(timeit.timeit(stmt='np.linalg.inv(A).dot(b)',setup='import numpy as np; A = np.random.rand(1000,1000); b = np.random.rand(1000,1)',number=100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can either use `linalg.inv()` and `linalg.dot()` methods in chain to solve a system of linear equations, or you can simply use the `solve()` method. The `solve()` method is the preferred way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overdetermined systems\n",
    "A system of linear equations is considered overdetermined if there are more equations than unknowns. For example, we have the overdetermined system\n",
    "\n",
    "$$x_1 + x_2 =2 \\\\\n",
    "x_1 = 1\\\\\n",
    "x_2 = 0$$\n",
    "\n",
    "In practice, we have a system $Ax=b$ where $A$ is a $m$ by $n$ matrix and $b$ is a $m$ dimensional vector, but $m$ is greater than $n$. In this case, the vector $b$ cannot be expressed as a linear combination of the columns of $A$. Hence, we can't find $x$ so that satisfies the problem $Ax=b$ (except in specific cases) but it is possible to determine $x$ so that $Ax$ is as close to $b$ as possible. So we wish to find $x$ which minimizes  $\\begin{Vmatrix}Ax-b\\end{Vmatrix}$. Considering the [QR decomposition](https://en.wikipedia.org/wiki/QR_decomposition) of $A$, we have that $Ax=b$ becomes $QRx=b$. Multiplying by $Q^T$ we obtain $Q^TQRx=Q^Tb$, and since $Q^T$ is orthogonal (this means that Q^T*Q=I) we have $Rx=Q^Tb$.\n",
    "\n",
    "Now, this is a well defined system, $R$ is an upper triangular matrix and $Q^T*b$ is a vector. More precisely $b$ is the orthogonal projection of $b$ onto the range of $A$ and $\\begin{Vmatrix}Ax-b\\end{Vmatrix}=\\begin{Vmatrix}Rx-Q^Tb\\end{Vmatrix}$.\n",
    "\n",
    "The function `linalg.lstsq()` provided by numpy returns the least-squares solution to a linear system equation and is able to solve overdetermined systems. Let's compare the solutions of `linalg.lstsq()` with the ones computed using the QR decomposition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.33333333 0.33333333]\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[1, 1], [1, 0],[0, 1]])\n",
    "b = np.array([2, 1, 0])\n",
    "x = np.linalg.lstsq(A,b,rcond=None)[0]\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.33333333 0.33333333]\n"
     ]
    }
   ],
   "source": [
    "Q,R = np.linalg.qr(A) # qr decomposition of A\n",
    "Qb = np.dot(Q.T,b) # computing Q^T*b (project b onto the range of A)\n",
    "x = np.linalg.solve(R,Qb) # solving R*x = Q^T*b\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the solutions are the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the vector for which the norm of the residual $\\begin{Vmatrix}r\\end{Vmatrix}$ becomes minimal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.33333333  0.33333333  0.33333333]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5773502691896257"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r =  A.dot(x)-b\n",
    "print(r)\n",
    "np.linalg.norm(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An even simpler example $x=0$, $x=1$. Here the norm of the residual $\\begin{Vmatrix}Ax-b\\end{Vmatrix}$ is\n",
    "\n",
    "$$\\begin{Vmatrix}r\\end{Vmatrix}=\\sqrt{x^2+(x-1)^2}$$\n",
    "\n",
    "and minimising this function (by finding the zero of the derivative) yields $x=1/2$. This is indeed what numpy returns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5]\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[1], [1]]);\n",
    "b = np.array([0, 1]);\n",
    "x = np.linalg.lstsq(A,b,rcond=None)[0]\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Underdetermined systems\n",
    "As an example consider\n",
    "$$x_1 + 2 x_2 + 3 x_3 + 4 x_4  = 1\\\\\n",
    "5 x_1 + 6 x_2 + 7 x_3 + 8 x_4 = 2$$\n",
    "This has an infinite number of solutions. `lstsq` returns one solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.05   0.025  0.1    0.175]\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[1,2,3,4],[5,6,7,8]])\n",
    "b = np.array([1,2])\n",
    "x = np.linalg.lstsq(A,b,rcond=None)[0]\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `scipy.optimize.nnls`, a non-negative least squares solver. Solve $argmin_x \\begin{Vmatrix}Ax - b\\end{Vmatrix}_2$ for $x\\ge0$, returns a solution with as many components as possible equal to zero. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.65502277e-16 0.00000000e+00 0.00000000e+00 2.50000000e-01]\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "from scipy.optimize import nnls \n",
    "x, rnorm = nnls(A,b)\n",
    "print(x)\n",
    "print(rnorm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find all solutions, we need to determine the kernel of $A$. The nullspace or kernel of a matrix $A$ (denoted $\\ker A$) is the set of all vectors $x$, for which $Ax=0$. If $x$ and $y$ are in the nullspace, then $c_1x+c_2y$ is also in the nullspace as \n",
    "\n",
    "$$A(c_1x+c_2y)=c_1(Ax)+c_2(Ay)=0+0=0$$\n",
    "\n",
    "The nullspace is a vector space. When $A$ is viewed as a linear transformation, the nullspace is the subspace of $\\mathcal{R}^n$ that is sent to 0 under the map $A$, hence the term \"fundamental subspace.\"\n",
    "\n",
    "An orthonormal basis $N=(n_1,\\dots,n_k)$ of the kernel is returned by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.40008743 -0.37407225]\n",
      " [ 0.25463292  0.79697056]\n",
      " [ 0.69099646 -0.47172438]\n",
      " [-0.54554195  0.04882607]]\n"
     ]
    }
   ],
   "source": [
    "from scipy.linalg import null_space, orth\n",
    "N = null_space(A)\n",
    "print(N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The nullspace consists of all vectors $x$ such that $Ax=0$. This defines a system of linear equations that can be solved to give the family of solutions\n",
    "\n",
    "$$$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "n0=N[:,0]\n",
    "n1=N[:,1]\n",
    "assert (abs(A.dot(n0))<=1e-14).all(), \"Ax=0 for all x in nullspace {}\".format(A.dot(n1))\n",
    "assert (abs(A.dot(n1))<=1e-14).all(), \"Ax=0 for all x in nullspace {}\".format(A.dot(n1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which defines a vector space with basis $\\{n_0,n_1\\}$. As there are two vectors in this basis, the dimension of the nullspace is 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column space: [[-0.31994238 -0.36841839]\n",
      " [-0.41936816  0.88119879]\n",
      " [-0.84956884 -0.29623738]]\n",
      "row space: [[-0.25358142  0.17588223]\n",
      " [-0.27620609 -0.66896915]\n",
      " [-0.76074427  0.52764668]\n",
      " [-0.52978752 -0.49308692]]\n",
      "nullspace: [[-0.94415867 -0.11543961]\n",
      " [ 0.03383545 -0.68923555]\n",
      " [ 0.32599804 -0.19126531]\n",
      " [-0.03383545  0.68923555]]\n",
      "left nullspace: [[ 0.87287156]\n",
      " [ 0.21821789]\n",
      " [-0.43643578]]\n"
     ]
    }
   ],
   "source": [
    "# example fundamental subspaces\n",
    "A = np.array([[1,2,3,3],[2,0,6,2],[3,4,9,7]])\n",
    "# column/row space (image)\n",
    "print('column space: {}'.format(orth(A)))\n",
    "print('row space: {}'.format(orth(A.T)))\n",
    "# nullspace/ left nullspace (kernel)\n",
    "print('nullspace: {}'.format(null_space(A)))\n",
    "print('left nullspace: {}'.format(null_space(A.T)))\n",
    "assert (abs(A.dot(null_space(A)))<=1e-14).all(), \"Ax=0 for all x in nullspace {}\".format(A.dot(null_space(A)))\n",
    "# Fundamental Theorem of Linear Algebra: rank-nullity theorem (relates the dimensions of the four fundamental subspaces)\n",
    "assert np.linalg.matrix_rank(A)==len(orth(A)[0])==len(orth(A.T)[0]), \"The column and row spaces of an m×n matrix A both have dimension r, the rank of the matrix.\"\n",
    "assert A.shape[1]-np.linalg.matrix_rank(A)==len(null_space(A)[1]), \"The nullspace has dimension n−r.\"\n",
    "assert A.shape[0]-np.linalg.matrix_rank(A.T)==len(null_space(A.T)[1]), \"The left nullspace has dimension m−r.\"\n",
    "# Fundamental Theorem of Linear Algebra: orthogonal spaces (the dot product v⋅w is 0)\n",
    "assert (abs(null_space(A).T.dot(orth(A.T)))<=1e-14).all(), \"The nullspace and row space are orthogonal.\"\n",
    "assert (abs(null_space(A.T).T.dot(orth(A)))<=1e-14).all(), \"The left nullspace and the column space are also orthogonal.\"\n",
    "# Fundamental Theorem of Linear Algebra:  orthonormal basis (singular value decomposition)\n",
    "[U,s,V]=np.linalg.svd(A)\n",
    "S = np.zeros(A.shape, dtype=complex)\n",
    "S[:(A.shape[0]), :(A.shape[0])] = np.diag(s)\n",
    "assert np.allclose(A, np.dot(U, np.dot(S, V))), \"any matrix M can be written as dot product of an m x m unitary martix, an m x n matrix with nonnegative values in diagonal, and an b x n unitary matrix.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using sympy to solve the equation set symbolically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{x_1: x_3 + 2*x_4 - 1/2, x_2: -2*x_3 - 3*x_4 + 3/4}\n"
     ]
    }
   ],
   "source": [
    "from sympy import * \n",
    "\n",
    "x_1, x_2, x_3, x_4 = symbols('x_1 x_2 x_3 x_4')\n",
    "\n",
    "res = solve([Eq(1*x_1+2*x_2+3*x_3+4*x_4, 1),\n",
    "             Eq(5*x_1+6*x_2+7*x_3+8*x_4, 2)],\n",
    "             [x_1, x_2, x_3, x_4])\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
